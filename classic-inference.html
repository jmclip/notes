<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lecture 12 Classical statistical inference | Computational Math Camp</title>
  <meta name="description" content="Contains lecture notes for the 2022 Computational Math Camp." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Lecture 12 Classical statistical inference | Computational Math Camp" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Contains lecture notes for the 2022 Computational Math Camp." />
  <meta name="github-repo" content="math-camp/notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lecture 12 Classical statistical inference | Computational Math Camp" />
  
  <meta name="twitter:description" content="Contains lecture notes for the 2022 Computational Math Camp." />
  



<meta name="date" content="2022-08-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="limits.html"/>
<link rel="next" href="mle-ols.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
\[
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\se}{\text{se}}
\newcommand{\sd}{\text{sd}}
\newcommand{\Cor}{\mathrm{Cor}}
\newcommand{\Lagr}{\mathcal{L}}
\newcommand{\lagr}{\mathcal{l}}
\]


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#meeting-information"><i class="fa fa-check"></i>Meeting information</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#instructional-staff"><i class="fa fa-check"></i>Instructional staff</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#teaching-assistants"><i class="fa fa-check"></i>Teaching assistants</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-description"><i class="fa fa-check"></i>Course description</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-should-take-this-course"><i class="fa fa-check"></i>Who should take this course</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#grades"><i class="fa fa-check"></i>Grades</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#disability-services"><i class="fa fa-check"></i>Disability services</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#core-texts"><i class="fa fa-check"></i>Core texts</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-format"><i class="fa fa-check"></i>Course format</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#problem-sets"><i class="fa fa-check"></i>Problem sets</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-schedule"><i class="fa fa-check"></i>Course schedule</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="sets-functions.html"><a href="sets-functions.html"><i class="fa fa-check"></i><b>1</b> Linear equations, inequalities, sets and functions, quadratics, and logarithms</a>
<ul>
<li class="chapter" data-level="" data-path="sets-functions.html"><a href="sets-functions.html#learning-objectives"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="sets-functions.html"><a href="sets-functions.html#supplemental-readings"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="1.1" data-path="sets-functions.html"><a href="sets-functions.html#what-is-computational-social-science"><i class="fa fa-check"></i><b>1.1</b> What is computational social science?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="sets-functions.html"><a href="sets-functions.html#disciplines-within-social-science"><i class="fa fa-check"></i><b>1.1.1</b> Disciplines within social science</a></li>
<li class="chapter" data-level="1.1.2" data-path="sets-functions.html"><a href="sets-functions.html#computational-social-science"><i class="fa fa-check"></i><b>1.1.2</b> Computational social science</a></li>
<li class="chapter" data-level="1.1.3" data-path="sets-functions.html"><a href="sets-functions.html#acquiring-css-skills"><i class="fa fa-check"></i><b>1.1.3</b> Acquiring CSS skills</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="sets-functions.html"><a href="sets-functions.html#difference-between-math-probability-and-statistics"><i class="fa fa-check"></i><b>1.2</b> Difference between math, probability, and statistics</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="sets-functions.html"><a href="sets-functions.html#mathematics"><i class="fa fa-check"></i><b>1.2.1</b> Mathematics</a></li>
<li class="chapter" data-level="1.2.2" data-path="sets-functions.html"><a href="sets-functions.html#probability"><i class="fa fa-check"></i><b>1.2.2</b> Probability</a></li>
<li class="chapter" data-level="1.2.3" data-path="sets-functions.html"><a href="sets-functions.html#statistics"><i class="fa fa-check"></i><b>1.2.3</b> Statistics</a></li>
<li class="chapter" data-level="1.2.4" data-path="sets-functions.html"><a href="sets-functions.html#their-uses"><i class="fa fa-check"></i><b>1.2.4</b> Their uses</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="sets-functions.html"><a href="sets-functions.html#goals-for-this-camp"><i class="fa fa-check"></i><b>1.3</b> Goals for this camp</a></li>
<li class="chapter" data-level="1.4" data-path="sets-functions.html"><a href="sets-functions.html#course-logistics"><i class="fa fa-check"></i><b>1.4</b> Course logistics</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="sets-functions.html"><a href="sets-functions.html#course-staff"><i class="fa fa-check"></i><b>1.4.1</b> Course staff</a></li>
<li class="chapter" data-level="1.4.2" data-path="sets-functions.html"><a href="sets-functions.html#teaching-assistants-1"><i class="fa fa-check"></i><b>1.4.2</b> Teaching assistants</a></li>
<li class="chapter" data-level="1.4.3" data-path="sets-functions.html"><a href="sets-functions.html#prerequisites-for-the-math-camp"><i class="fa fa-check"></i><b>1.4.3</b> Prerequisites for the math camp</a></li>
<li class="chapter" data-level="1.4.4" data-path="sets-functions.html"><a href="sets-functions.html#alternatives-to-this-camp"><i class="fa fa-check"></i><b>1.4.4</b> Alternatives to this camp</a></li>
<li class="chapter" data-level="1.4.5" data-path="sets-functions.html"><a href="sets-functions.html#evaluation"><i class="fa fa-check"></i><b>1.4.5</b> Evaluation</a></li>
<li class="chapter" data-level="1.4.6" data-path="sets-functions.html"><a href="sets-functions.html#why-are-we-doing-this"><i class="fa fa-check"></i><b>1.4.6</b> Why are we doing this</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="sets-functions.html"><a href="sets-functions.html#mathematical-notation"><i class="fa fa-check"></i><b>1.5</b> Mathematical notation</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="sets-functions.html"><a href="sets-functions.html#why-math-is-important-to-social-science"><i class="fa fa-check"></i><b>1.5.1</b> Why math is important to social science</a></li>
<li class="chapter" data-level="1.5.2" data-path="sets-functions.html"><a href="sets-functions.html#example-paradox-of-voting"><i class="fa fa-check"></i><b>1.5.2</b> Example: Paradox of voting</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="sets-functions.html"><a href="sets-functions.html#sets"><i class="fa fa-check"></i><b>1.6</b> Sets</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="sets-functions.html"><a href="sets-functions.html#set-builder-notation"><i class="fa fa-check"></i><b>1.6.1</b> Set builder notation</a></li>
<li class="chapter" data-level="1.6.2" data-path="sets-functions.html"><a href="sets-functions.html#set-operations"><i class="fa fa-check"></i><b>1.6.2</b> Set operations</a></li>
<li class="chapter" data-level="1.6.3" data-path="sets-functions.html"><a href="sets-functions.html#some-facts-about-sets"><i class="fa fa-check"></i><b>1.6.3</b> Some facts about sets</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="sets-functions.html"><a href="sets-functions.html#functions"><i class="fa fa-check"></i><b>1.7</b> Functions</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="sets-functions.html"><a href="sets-functions.html#ordered-pairs"><i class="fa fa-check"></i><b>1.7.1</b> Ordered pairs</a></li>
<li class="chapter" data-level="1.7.2" data-path="sets-functions.html"><a href="sets-functions.html#relation"><i class="fa fa-check"></i><b>1.7.2</b> Relation</a></li>
<li class="chapter" data-level="1.7.3" data-path="sets-functions.html"><a href="sets-functions.html#relation-vs.-function"><i class="fa fa-check"></i><b>1.7.3</b> Relation vs.Â function</a></li>
<li class="chapter" data-level="1.7.4" data-path="sets-functions.html"><a href="sets-functions.html#two-major-properties-of-functions"><i class="fa fa-check"></i><b>1.7.4</b> Two major properties of functions</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="sets-functions.html"><a href="sets-functions.html#quadratic-functions"><i class="fa fa-check"></i><b>1.8</b> Quadratic functions</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="sets-functions.html"><a href="sets-functions.html#quadratic-equation"><i class="fa fa-check"></i><b>1.8.1</b> Quadratic equation</a></li>
<li class="chapter" data-level="1.8.2" data-path="sets-functions.html"><a href="sets-functions.html#quadratic-formula"><i class="fa fa-check"></i><b>1.8.2</b> Quadratic formula</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="sets-functions.html"><a href="sets-functions.html#systems-of-linear-equations"><i class="fa fa-check"></i><b>1.9</b> Systems of linear equations</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="sets-functions.html"><a href="sets-functions.html#one-solution"><i class="fa fa-check"></i><b>1.9.1</b> One solution</a></li>
<li class="chapter" data-level="1.9.2" data-path="sets-functions.html"><a href="sets-functions.html#no-solution"><i class="fa fa-check"></i><b>1.9.2</b> No solution</a></li>
<li class="chapter" data-level="1.9.3" data-path="sets-functions.html"><a href="sets-functions.html#infinite-solutions"><i class="fa fa-check"></i><b>1.9.3</b> Infinite solutions</a></li>
<li class="chapter" data-level="1.9.4" data-path="sets-functions.html"><a href="sets-functions.html#three-equations-in-three-unknowns"><i class="fa fa-check"></i><b>1.9.4</b> Three equations in three unknowns</a></li>
<li class="chapter" data-level="1.9.5" data-path="sets-functions.html"><a href="sets-functions.html#gaussian-elimination"><i class="fa fa-check"></i><b>1.9.5</b> Gaussian elimination</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="sets-functions.html"><a href="sets-functions.html#logarithms-and-exponential-functions"><i class="fa fa-check"></i><b>1.10</b> Logarithms and exponential functions</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="sets-functions.html"><a href="sets-functions.html#functions-with-exponents"><i class="fa fa-check"></i><b>1.10.1</b> Functions with exponents</a></li>
<li class="chapter" data-level="1.10.2" data-path="sets-functions.html"><a href="sets-functions.html#common-rules-of-exponents"><i class="fa fa-check"></i><b>1.10.2</b> Common rules of exponents</a></li>
<li class="chapter" data-level="1.10.3" data-path="sets-functions.html"><a href="sets-functions.html#logarithms"><i class="fa fa-check"></i><b>1.10.3</b> Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="sets-functions.html"><a href="sets-functions.html#bonus-content-computational-tools-for-the-future"><i class="fa fa-check"></i><b>1.11</b> Bonus content: Computational tools for the future</a>
<ul>
<li class="chapter" data-level="1.11.1" data-path="sets-functions.html"><a href="sets-functions.html#programming-languages-for-statistical-learning"><i class="fa fa-check"></i><b>1.11.1</b> Programming languages for statistical learning</a></li>
<li class="chapter" data-level="1.11.2" data-path="sets-functions.html"><a href="sets-functions.html#version-control-git"><i class="fa fa-check"></i><b>1.11.2</b> Version control (Git)</a></li>
<li class="chapter" data-level="1.11.3" data-path="sets-functions.html"><a href="sets-functions.html#publishing"><i class="fa fa-check"></i><b>1.11.3</b> Publishing</a></li>
<li class="chapter" data-level="1.11.4" data-path="sets-functions.html"><a href="sets-functions.html#how-will-you-acquire-these-skills"><i class="fa fa-check"></i><b>1.11.4</b> How will you acquire these skills?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html"><i class="fa fa-check"></i><b>2</b> Sequences, limits, continuity, and derivatives</a>
<ul>
<li class="chapter" data-level="" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#learning-objectives-1"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#supplemental-readings-1"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="2.1" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#sequence"><i class="fa fa-check"></i><b>2.1</b> Sequence</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#definition"><i class="fa fa-check"></i><b>2.1.1</b> Definition</a></li>
<li class="chapter" data-level="2.1.2" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#examples"><i class="fa fa-check"></i><b>2.1.2</b> Examples</a></li>
<li class="chapter" data-level="2.1.3" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#arithmetic-and-geometric-progressions"><i class="fa fa-check"></i><b>2.1.3</b> Arithmetic and geometric progressions</a></li>
<li class="chapter" data-level="2.1.4" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#convergence"><i class="fa fa-check"></i><b>2.1.4</b> Convergence</a></li>
<li class="chapter" data-level="2.1.5" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#algebra-of-sequences"><i class="fa fa-check"></i><b>2.1.5</b> Algebra of sequences</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#limits"><i class="fa fa-check"></i><b>2.2</b> Limits</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#sequences-leadsto-limits-of-functions"><i class="fa fa-check"></i><b>2.2.1</b> Sequences <span class="math inline">\(\leadsto\)</span> limits of functions</a></li>
<li class="chapter" data-level="2.2.2" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#limits-of-functions"><i class="fa fa-check"></i><b>2.2.2</b> Limits of functions</a></li>
<li class="chapter" data-level="2.2.3" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#examples-of-limits"><i class="fa fa-check"></i><b>2.2.3</b> Examples of limits</a></li>
<li class="chapter" data-level="2.2.4" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#not-all-functions-have-limits"><i class="fa fa-check"></i><b>2.2.4</b> Not all functions have limits</a></li>
<li class="chapter" data-level="2.2.5" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#intuitive-definition-of-a-limit"><i class="fa fa-check"></i><b>2.2.5</b> Intuitive definition of a limit</a></li>
<li class="chapter" data-level="2.2.6" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#algebra-of-limits"><i class="fa fa-check"></i><b>2.2.6</b> Algebra of limits</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#continuity"><i class="fa fa-check"></i><b>2.3</b> Continuity</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#defining-continuity"><i class="fa fa-check"></i><b>2.3.1</b> Defining continuity</a></li>
<li class="chapter" data-level="2.3.2" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#a-real-world-example-of-limits-measuring-incumbency-advantage"><i class="fa fa-check"></i><b>2.3.2</b> A real-world example of limits: Measuring incumbency advantage</a></li>
<li class="chapter" data-level="2.3.3" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#continuity-and-limits"><i class="fa fa-check"></i><b>2.3.3</b> Continuity and limits</a></li>
<li class="chapter" data-level="2.3.4" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#algebra-of-continuous-functions"><i class="fa fa-check"></i><b>2.3.4</b> Algebra of continuous functions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#what-is-calculus"><i class="fa fa-check"></i><b>2.4</b> What is calculus?</a></li>
<li class="chapter" data-level="2.5" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#derivatives"><i class="fa fa-check"></i><b>2.5</b> Derivatives</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#how-functions-change"><i class="fa fa-check"></i><b>2.5.1</b> How functions change</a></li>
<li class="chapter" data-level="2.5.2" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#the-tangent-as-a-limit"><i class="fa fa-check"></i><b>2.5.2</b> The tangent as a limit</a></li>
<li class="chapter" data-level="2.5.3" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#derivative"><i class="fa fa-check"></i><b>2.5.3</b> Derivative</a></li>
<li class="chapter" data-level="2.5.4" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#rates-of-change-in-a-function"><i class="fa fa-check"></i><b>2.5.4</b> Rates of change in a function</a></li>
<li class="chapter" data-level="2.5.5" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#examples-of-derivatives"><i class="fa fa-check"></i><b>2.5.5</b> Examples of derivatives</a></li>
<li class="chapter" data-level="2.5.6" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#continuity-and-derivatives"><i class="fa fa-check"></i><b>2.5.6</b> Continuity and derivatives</a></li>
<li class="chapter" data-level="2.5.7" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#what-goes-wrong"><i class="fa fa-check"></i><b>2.5.7</b> What goes wrong?</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#calculating-derivatives"><i class="fa fa-check"></i><b>2.6</b> Calculating derivatives</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#derivative-rules"><i class="fa fa-check"></i><b>2.6.1</b> Derivative rules</a></li>
<li class="chapter" data-level="2.6.2" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#challenge-problems"><i class="fa fa-check"></i><b>2.6.2</b> Challenge problems</a></li>
<li class="chapter" data-level="2.6.3" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#composite-functions"><i class="fa fa-check"></i><b>2.6.3</b> Composite functions</a></li>
<li class="chapter" data-level="2.6.4" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#chain-rule"><i class="fa fa-check"></i><b>2.6.4</b> Chain rule</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#derivatives-for-the-exponential-function-and-natural-logarithms"><i class="fa fa-check"></i><b>2.7</b> Derivatives for the exponential function and natural logarithms</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#derivative-of-exponential-function"><i class="fa fa-check"></i><b>2.7.1</b> Derivative of exponential function</a></li>
<li class="chapter" data-level="2.7.2" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#derivative-of-the-natural-logarithm"><i class="fa fa-check"></i><b>2.7.2</b> Derivative of the natural logarithm</a></li>
<li class="chapter" data-level="2.7.3" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#relevance-of-exponential-functions-and-natural-logarithm"><i class="fa fa-check"></i><b>2.7.3</b> Relevance of exponential functions and natural logarithm</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#derivatives-and-properties-of-functions"><i class="fa fa-check"></i><b>2.8</b> Derivatives and properties of functions</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#relative-maxima-minima-and-derivatives"><i class="fa fa-check"></i><b>2.8.1</b> Relative maxima, minima and derivatives</a></li>
<li class="chapter" data-level="2.8.2" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#mean-value-theorem"><i class="fa fa-check"></i><b>2.8.2</b> Mean value theorem</a></li>
<li class="chapter" data-level="2.8.3" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#applications-of-the-mean-value-theorem"><i class="fa fa-check"></i><b>2.8.3</b> Applications of the mean value theorem</a></li>
<li class="chapter" data-level="2.8.4" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#extension-to-indeterminate-form-limits"><i class="fa fa-check"></i><b>2.8.4</b> Extension to indeterminate form limits</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="critical-points.html"><a href="critical-points.html"><i class="fa fa-check"></i><b>3</b> Critical points and approximation</a>
<ul>
<li class="chapter" data-level="" data-path="critical-points.html"><a href="critical-points.html#learning-objectives-2"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="critical-points.html"><a href="critical-points.html#supplemental-readings-2"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="3.1" data-path="critical-points.html"><a href="critical-points.html#intuition"><i class="fa fa-check"></i><b>3.1</b> Intuition</a></li>
<li class="chapter" data-level="3.2" data-path="critical-points.html"><a href="critical-points.html#higher-order-derivatives"><i class="fa fa-check"></i><b>3.2</b> Higher order derivatives</a></li>
<li class="chapter" data-level="3.3" data-path="critical-points.html"><a href="critical-points.html#critical-points-1"><i class="fa fa-check"></i><b>3.3</b> Critical points</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="critical-points.html"><a href="critical-points.html#inflection-point"><i class="fa fa-check"></i><b>3.3.1</b> Inflection point</a></li>
<li class="chapter" data-level="3.3.2" data-path="critical-points.html"><a href="critical-points.html#concavity"><i class="fa fa-check"></i><b>3.3.2</b> Concavity</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="critical-points.html"><a href="critical-points.html#extrema"><i class="fa fa-check"></i><b>3.4</b> Extrema</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="critical-points.html"><a href="critical-points.html#minimum-and-maximum-on-the-interval-05-are-located-at-the-endpoints"><i class="fa fa-check"></i><b>3.4.1</b> Minimum and maximum on the interval <span class="math inline">\([0,5]\)</span> are located at the endpoints</a></li>
<li class="chapter" data-level="3.4.2" data-path="critical-points.html"><a href="critical-points.html#global-maximum-is-located-at-x0"><i class="fa fa-check"></i><b>3.4.2</b> Global maximum is located at <span class="math inline">\(x=0\)</span></a></li>
<li class="chapter" data-level="3.4.3" data-path="critical-points.html"><a href="critical-points.html#global-minimum-is-located-at-x---frac92"><i class="fa fa-check"></i><b>3.4.3</b> Global minimum is located at <span class="math inline">\(x= - \frac{9}{2}\)</span></a></li>
<li class="chapter" data-level="3.4.4" data-path="critical-points.html"><a href="critical-points.html#a-bunch-of-local-minima-and-maxima"><i class="fa fa-check"></i><b>3.4.4</b> A bunch of local minima and maxima</a></li>
<li class="chapter" data-level="3.4.5" data-path="critical-points.html"><a href="critical-points.html#x0-is-an-inflection-point-that-is-neither-a-minimum-nor-a-maximum-fx-0"><i class="fa fa-check"></i><b>3.4.5</b> <span class="math inline">\(x=0\)</span> is an inflection point that is neither a minimum nor a maximum (<span class="math inline">\(f&#39;&#39;(x) = 0\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="critical-points.html"><a href="critical-points.html#framework-for-analytical-optimization"><i class="fa fa-check"></i><b>3.5</b> Framework for analytical optimization</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="critical-points.html"><a href="critical-points.html#example-fx--x2-x-in--3-3"><i class="fa fa-check"></i><b>3.5.1</b> Example: <span class="math inline">\(f(x) = -x^2\)</span>, <span class="math inline">\(x \in [-3, 3]\)</span></a></li>
<li class="chapter" data-level="3.5.2" data-path="critical-points.html"><a href="critical-points.html#example-fx-x3-x-in--3-3"><i class="fa fa-check"></i><b>3.5.2</b> Example: <span class="math inline">\(f(x) = x^3\)</span>, <span class="math inline">\(x \in [-3, 3]\)</span></a></li>
<li class="chapter" data-level="3.5.3" data-path="critical-points.html"><a href="critical-points.html#example-spatial-model"><i class="fa fa-check"></i><b>3.5.3</b> Example: spatial model</a></li>
<li class="chapter" data-level="3.5.4" data-path="critical-points.html"><a href="critical-points.html#example-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>3.5.4</b> Example: Maximum likelihood estimation</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="critical-points.html"><a href="critical-points.html#computational-optimization-procedures"><i class="fa fa-check"></i><b>3.6</b> Computational optimization procedures</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="critical-points.html"><a href="critical-points.html#newton-raphson-root-finding"><i class="fa fa-check"></i><b>3.6.1</b> Newton-Raphson root finding</a></li>
<li class="chapter" data-level="3.6.2" data-path="critical-points.html"><a href="critical-points.html#grid-search"><i class="fa fa-check"></i><b>3.6.2</b> Grid search</a></li>
<li class="chapter" data-level="3.6.3" data-path="critical-points.html"><a href="critical-points.html#gradient-descent"><i class="fa fa-check"></i><b>3.6.3</b> Gradient descent</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>4</b> Linear algebra</a>
<ul>
<li class="chapter" data-level="" data-path="linear-algebra.html"><a href="linear-algebra.html#learning-objectives-3"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="linear-algebra.html"><a href="linear-algebra.html#supplemental-readings-3"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="4.1" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-algebra-1"><i class="fa fa-check"></i><b>4.1</b> Linear algebra</a></li>
<li class="chapter" data-level="4.2" data-path="linear-algebra.html"><a href="linear-algebra.html#points-and-vectors"><i class="fa fa-check"></i><b>4.2</b> Points and vectors</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="linear-algebra.html"><a href="linear-algebra.html#points"><i class="fa fa-check"></i><b>4.2.1</b> Points</a></li>
<li class="chapter" data-level="4.2.2" data-path="linear-algebra.html"><a href="linear-algebra.html#vectors"><i class="fa fa-check"></i><b>4.2.2</b> Vectors</a></li>
<li class="chapter" data-level="4.2.3" data-path="linear-algebra.html"><a href="linear-algebra.html#one-dimensional-example"><i class="fa fa-check"></i><b>4.2.3</b> One dimensional example</a></li>
<li class="chapter" data-level="4.2.4" data-path="linear-algebra.html"><a href="linear-algebra.html#two-dimensional-example"><i class="fa fa-check"></i><b>4.2.4</b> Two dimensional example</a></li>
<li class="chapter" data-level="4.2.5" data-path="linear-algebra.html"><a href="linear-algebra.html#three-dimensional-example"><i class="fa fa-check"></i><b>4.2.5</b> Three dimensional example</a></li>
<li class="chapter" data-level="4.2.6" data-path="linear-algebra.html"><a href="linear-algebra.html#n-dimensional-example"><i class="fa fa-check"></i><b>4.2.6</b> <span class="math inline">\(N\)</span>-dimensional example</a></li>
<li class="chapter" data-level="4.2.7" data-path="linear-algebra.html"><a href="linear-algebra.html#examples-of-some-basic-arithmetic"><i class="fa fa-check"></i><b>4.2.7</b> Examples of some basic arithmetic</a></li>
<li class="chapter" data-level="4.2.8" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-dependence"><i class="fa fa-check"></i><b>4.2.8</b> Linear dependence</a></li>
<li class="chapter" data-level="4.2.9" data-path="linear-algebra.html"><a href="linear-algebra.html#inner-product"><i class="fa fa-check"></i><b>4.2.9</b> Inner product</a></li>
<li class="chapter" data-level="4.2.10" data-path="linear-algebra.html"><a href="linear-algebra.html#calculating-vector-length"><i class="fa fa-check"></i><b>4.2.10</b> Calculating vector length</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-algebra.html"><a href="linear-algebra.html#example-text-analysis"><i class="fa fa-check"></i><b>4.3</b> Example: text analysis</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="linear-algebra.html"><a href="linear-algebra.html#measure-1-inner-product"><i class="fa fa-check"></i><b>4.3.1</b> Measure 1: inner product</a></li>
<li class="chapter" data-level="4.3.2" data-path="linear-algebra.html"><a href="linear-algebra.html#measure-2-cosine-similarity"><i class="fa fa-check"></i><b>4.3.2</b> Measure 2: cosine similarity</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linear-algebra.html"><a href="linear-algebra.html#matricies"><i class="fa fa-check"></i><b>4.4</b> Matricies</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="linear-algebra.html"><a href="linear-algebra.html#basic-arithmetic"><i class="fa fa-check"></i><b>4.4.1</b> Basic arithmetic</a></li>
<li class="chapter" data-level="4.4.2" data-path="linear-algebra.html"><a href="linear-algebra.html#transposition"><i class="fa fa-check"></i><b>4.4.2</b> Transposition</a></li>
<li class="chapter" data-level="4.4.3" data-path="linear-algebra.html"><a href="linear-algebra.html#multiplication"><i class="fa fa-check"></i><b>4.4.3</b> Multiplication</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="linear-algebra.html"><a href="linear-algebra.html#example-neural-networks"><i class="fa fa-check"></i><b>4.5</b> Example: neural networks</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="linear-algebra.html"><a href="linear-algebra.html#how-are-neural-networks-used"><i class="fa fa-check"></i><b>4.5.1</b> How are neural networks used</a></li>
<li class="chapter" data-level="4.5.2" data-path="linear-algebra.html"><a href="linear-algebra.html#how-are-neural-networks-related-to-linear-algebra"><i class="fa fa-check"></i><b>4.5.2</b> How are neural networks related to linear algebra?</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="linear-algebra.html"><a href="linear-algebra.html#matrix-inversion"><i class="fa fa-check"></i><b>4.6</b> Matrix inversion</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="linear-algebra.html"><a href="linear-algebra.html#calculating-matrix-inversions"><i class="fa fa-check"></i><b>4.6.1</b> Calculating matrix inversions</a></li>
<li class="chapter" data-level="4.6.2" data-path="linear-algebra.html"><a href="linear-algebra.html#when-do-inverses-exist"><i class="fa fa-check"></i><b>4.6.2</b> When do inverses exist</a></li>
<li class="chapter" data-level="4.6.3" data-path="linear-algebra.html"><a href="linear-algebra.html#inverting-a-2-times-2-matrix"><i class="fa fa-check"></i><b>4.6.3</b> Inverting a <span class="math inline">\(2 \times 2\)</span> matrix</a></li>
<li class="chapter" data-level="4.6.4" data-path="linear-algebra.html"><a href="linear-algebra.html#inverting-an-n-times-n-matrix"><i class="fa fa-check"></i><b>4.6.4</b> Inverting an <span class="math inline">\(n \times n\)</span> matrix</a></li>
<li class="chapter" data-level="4.6.5" data-path="linear-algebra.html"><a href="linear-algebra.html#application-to-regression-analysis"><i class="fa fa-check"></i><b>4.6.5</b> Application to regression analysis</a></li>
<li class="chapter" data-level="4.6.6" data-path="linear-algebra.html"><a href="linear-algebra.html#application-to-solving-systems-of-equations-tax-benefits-of-charitable-contributions"><i class="fa fa-check"></i><b>4.6.6</b> Application to solving systems of equations: tax benefits of charitable contributions</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="linear-algebra.html"><a href="linear-algebra.html#determinant"><i class="fa fa-check"></i><b>4.7</b> Determinant</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="linear-algebra.html"><a href="linear-algebra.html#relevance-of-the-determinant"><i class="fa fa-check"></i><b>4.7.1</b> Relevance of the determinant</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="linear-algebra.html"><a href="linear-algebra.html#matrix-decomposition"><i class="fa fa-check"></i><b>4.8</b> Matrix decomposition</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="linear-algebra.html"><a href="linear-algebra.html#dimension-reduction"><i class="fa fa-check"></i><b>4.8.1</b> Dimension reduction</a></li>
<li class="chapter" data-level="4.8.2" data-path="linear-algebra.html"><a href="linear-algebra.html#singular-value-decomposition"><i class="fa fa-check"></i><b>4.8.2</b> Singular value decomposition</a></li>
<li class="chapter" data-level="4.8.3" data-path="linear-algebra.html"><a href="linear-algebra.html#principal-components-analysis"><i class="fa fa-check"></i><b>4.8.3</b> Principal components analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="linear-algebra.html"><a href="linear-algebra.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html"><i class="fa fa-check"></i><b>5</b> Functions of several variables and optimization with several variables</a>
<ul>
<li class="chapter" data-level="" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#learning-objectives-4"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#supplemental-readings-4"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="5.1" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#higher-order-derivatives-1"><i class="fa fa-check"></i><b>5.1</b> Higher order derivatives</a></li>
<li class="chapter" data-level="5.2" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#multivariate-function"><i class="fa fa-check"></i><b>5.2</b> Multivariate function</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#definition-2"><i class="fa fa-check"></i><b>5.2.1</b> Definition</a></li>
<li class="chapter" data-level="5.2.2" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#evaluating-multivariate-functions"><i class="fa fa-check"></i><b>5.2.2</b> Evaluating multivariate functions</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#multivariate-derivatives"><i class="fa fa-check"></i><b>5.3</b> Multivariate derivatives</a></li>
<li class="chapter" data-level="5.4" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#multivariate-optimization"><i class="fa fa-check"></i><b>5.4</b> Multivariate optimization</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#differences-from-single-variable-optimization-procedure"><i class="fa fa-check"></i><b>5.4.1</b> Differences from single variable optimization procedure</a></li>
<li class="chapter" data-level="5.4.2" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#first-derivative-test-gradient"><i class="fa fa-check"></i><b>5.4.2</b> First derivative test: Gradient</a></li>
<li class="chapter" data-level="5.4.3" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#second-derivative-test-hessian"><i class="fa fa-check"></i><b>5.4.3</b> Second derivative test: Hessian</a></li>
<li class="chapter" data-level="5.4.4" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#basic-procedure-summarized"><i class="fa fa-check"></i><b>5.4.4</b> Basic procedure summarized</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#a-simple-optimization-example"><i class="fa fa-check"></i><b>5.5</b> A simple optimization example</a></li>
<li class="chapter" data-level="5.6" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#maximum-likelihood-estimation-for-a-normal-distribution"><i class="fa fa-check"></i><b>5.6</b> Maximum likelihood estimation for a normal distribution</a></li>
<li class="chapter" data-level="5.7" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#computational-optimization-procedures-1"><i class="fa fa-check"></i><b>5.7</b> Computational optimization procedures</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#multivariate-newton-raphson"><i class="fa fa-check"></i><b>5.7.1</b> Multivariate Newton-Raphson</a></li>
<li class="chapter" data-level="5.7.2" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#grid-search-1"><i class="fa fa-check"></i><b>5.7.2</b> Grid search</a></li>
<li class="chapter" data-level="5.7.3" data-path="multivariable-differentiation.html"><a href="multivariable-differentiation.html#gradient-descent-1"><i class="fa fa-check"></i><b>5.7.3</b> Gradient descent</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="integral-calculus.html"><a href="integral-calculus.html"><i class="fa fa-check"></i><b>6</b> Integration and integral calculus</a>
<ul>
<li class="chapter" data-level="" data-path="integral-calculus.html"><a href="integral-calculus.html#learning-objectives-5"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="integral-calculus.html"><a href="integral-calculus.html#supplemental-readings-5"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="6.1" data-path="integral-calculus.html"><a href="integral-calculus.html#prepare-for-the-journey"><i class="fa fa-check"></i><b>6.1</b> Prepare for the journey</a></li>
<li class="chapter" data-level="6.2" data-path="integral-calculus.html"><a href="integral-calculus.html#indefinite-integration"><i class="fa fa-check"></i><b>6.2</b> Indefinite integration</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="integral-calculus.html"><a href="integral-calculus.html#many-possible-antiderivatives"><i class="fa fa-check"></i><b>6.2.1</b> Many possible antiderivatives</a></li>
<li class="chapter" data-level="6.2.2" data-path="integral-calculus.html"><a href="integral-calculus.html#common-rules-of-integration"><i class="fa fa-check"></i><b>6.2.2</b> Common rules of integration</a></li>
<li class="chapter" data-level="6.2.3" data-path="integral-calculus.html"><a href="integral-calculus.html#practice-integrating-functions"><i class="fa fa-check"></i><b>6.2.3</b> Practice integrating functions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="integral-calculus.html"><a href="integral-calculus.html#the-definite-integral-area-under-the-curve"><i class="fa fa-check"></i><b>6.3</b> The definite integral: area under the curve</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="integral-calculus.html"><a href="integral-calculus.html#the-definite-integral-riemann"><i class="fa fa-check"></i><b>6.3.1</b> The definite integral (Riemann)</a></li>
<li class="chapter" data-level="6.3.2" data-path="integral-calculus.html"><a href="integral-calculus.html#counterexamples"><i class="fa fa-check"></i><b>6.3.2</b> Counterexamples</a></li>
<li class="chapter" data-level="6.3.3" data-path="integral-calculus.html"><a href="integral-calculus.html#fundamental-theorem-of-calculus"><i class="fa fa-check"></i><b>6.3.3</b> Fundamental theorem of calculus</a></li>
<li class="chapter" data-level="6.3.4" data-path="integral-calculus.html"><a href="integral-calculus.html#common-rules-for-definite-integrals"><i class="fa fa-check"></i><b>6.3.4</b> Common rules for definite integrals</a></li>
<li class="chapter" data-level="6.3.5" data-path="integral-calculus.html"><a href="integral-calculus.html#practice-solving-definite-integrals"><i class="fa fa-check"></i><b>6.3.5</b> Practice solving definite integrals</a></li>
<li class="chapter" data-level="6.3.6" data-path="integral-calculus.html"><a href="integral-calculus.html#integration-by-substitution"><i class="fa fa-check"></i><b>6.3.6</b> Integration by substitution</a></li>
<li class="chapter" data-level="6.3.7" data-path="integral-calculus.html"><a href="integral-calculus.html#integration-by-parts"><i class="fa fa-check"></i><b>6.3.7</b> Integration by parts</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="integral-calculus.html"><a href="integral-calculus.html#infinite-integrals"><i class="fa fa-check"></i><b>6.4</b> Infinite integrals</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="integral-calculus.html"><a href="integral-calculus.html#two-sided-infinite-integrals"><i class="fa fa-check"></i><b>6.4.1</b> Two-sided infinite integrals</a></li>
<li class="chapter" data-level="6.4.2" data-path="integral-calculus.html"><a href="integral-calculus.html#improper-integrals"><i class="fa fa-check"></i><b>6.4.2</b> Improper integrals</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="integral-calculus.html"><a href="integral-calculus.html#monte-carlo-and-integration"><i class="fa fa-check"></i><b>6.5</b> Monte Carlo and integration</a></li>
<li class="chapter" data-level="6.6" data-path="integral-calculus.html"><a href="integral-calculus.html#multivariate-integration"><i class="fa fa-check"></i><b>6.6</b> Multivariate integration</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="integral-calculus.html"><a href="integral-calculus.html#more-complicated-bounds-of-integration"><i class="fa fa-check"></i><b>6.6.1</b> More complicated bounds of integration</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="integral-calculus.html"><a href="integral-calculus.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sample-space-probability.html"><a href="sample-space-probability.html"><i class="fa fa-check"></i><b>7</b> Sample space and probability</a>
<ul>
<li class="chapter" data-level="" data-path="sample-space-probability.html"><a href="sample-space-probability.html#learning-objectives-6"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="sample-space-probability.html"><a href="sample-space-probability.html#supplemental-readings-6"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="7.1" data-path="sample-space-probability.html"><a href="sample-space-probability.html#model-of-probability"><i class="fa fa-check"></i><b>7.1</b> Model of probability</a></li>
<li class="chapter" data-level="7.2" data-path="sample-space-probability.html"><a href="sample-space-probability.html#sample-space"><i class="fa fa-check"></i><b>7.2</b> Sample space</a></li>
<li class="chapter" data-level="7.3" data-path="sample-space-probability.html"><a href="sample-space-probability.html#events"><i class="fa fa-check"></i><b>7.3</b> Events</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="sample-space-probability.html"><a href="sample-space-probability.html#event-operations"><i class="fa fa-check"></i><b>7.3.1</b> Event operations</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="sample-space-probability.html"><a href="sample-space-probability.html#probability-1"><i class="fa fa-check"></i><b>7.4</b> Probability</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="sample-space-probability.html"><a href="sample-space-probability.html#three-axioms"><i class="fa fa-check"></i><b>7.4.1</b> Three axioms</a></li>
<li class="chapter" data-level="7.4.2" data-path="sample-space-probability.html"><a href="sample-space-probability.html#basic-examples"><i class="fa fa-check"></i><b>7.4.2</b> Basic examples</a></li>
<li class="chapter" data-level="7.4.3" data-path="sample-space-probability.html"><a href="sample-space-probability.html#surprising-probability-facts"><i class="fa fa-check"></i><b>7.4.3</b> Surprising probability facts</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="sample-space-probability.html"><a href="sample-space-probability.html#conditional-probability"><i class="fa fa-check"></i><b>7.5</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="sample-space-probability.html"><a href="sample-space-probability.html#examples-1"><i class="fa fa-check"></i><b>7.5.1</b> Examples</a></li>
<li class="chapter" data-level="7.5.2" data-path="sample-space-probability.html"><a href="sample-space-probability.html#difference-between-prab-and-prba"><i class="fa fa-check"></i><b>7.5.2</b> Difference between <span class="math inline">\(\Pr(A|B)\)</span> and <span class="math inline">\(\Pr(B|A)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="sample-space-probability.html"><a href="sample-space-probability.html#law-of-total-probability"><i class="fa fa-check"></i><b>7.6</b> Law of total probability</a></li>
<li class="chapter" data-level="7.7" data-path="sample-space-probability.html"><a href="sample-space-probability.html#bayes-rule"><i class="fa fa-check"></i><b>7.7</b> Bayesâ Rule</a></li>
<li class="chapter" data-level="7.8" data-path="sample-space-probability.html"><a href="sample-space-probability.html#independence-of-probabilities"><i class="fa fa-check"></i><b>7.8</b> Independence of probabilities</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="sample-space-probability.html"><a href="sample-space-probability.html#rolling-a-4-sided-die"><i class="fa fa-check"></i><b>7.8.1</b> Rolling a 4-sided die</a></li>
<li class="chapter" data-level="7.8.2" data-path="sample-space-probability.html"><a href="sample-space-probability.html#independence-and-causal-inference"><i class="fa fa-check"></i><b>7.8.2</b> Independence and causal inference</a></li>
<li class="chapter" data-level="7.8.3" data-path="sample-space-probability.html"><a href="sample-space-probability.html#independence-of-a-collection-of-events"><i class="fa fa-check"></i><b>7.8.3</b> Independence of a collection of events</a></li>
<li class="chapter" data-level="7.8.4" data-path="sample-space-probability.html"><a href="sample-space-probability.html#independent-trials-and-the-binomial-probabilities"><i class="fa fa-check"></i><b>7.8.4</b> Independent trials and the binomial probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="sample-space-probability.html"><a href="sample-space-probability.html#counting"><i class="fa fa-check"></i><b>7.9</b> Counting</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="sample-space-probability.html"><a href="sample-space-probability.html#counting-principle"><i class="fa fa-check"></i><b>7.9.1</b> Counting principle</a></li>
<li class="chapter" data-level="7.9.2" data-path="sample-space-probability.html"><a href="sample-space-probability.html#permutations"><i class="fa fa-check"></i><b>7.9.2</b> Permutations</a></li>
<li class="chapter" data-level="7.9.3" data-path="sample-space-probability.html"><a href="sample-space-probability.html#combinations"><i class="fa fa-check"></i><b>7.9.3</b> Combinations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>8</b> Discrete random variables</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#learning-objectives-7"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#supplemental-readings-7"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="8.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#random-variable"><i class="fa fa-check"></i><b>8.1</b> Random variable</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#discrete-random-variables-1"><i class="fa fa-check"></i><b>8.1.1</b> Discrete random variables</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-mass-functions"><i class="fa fa-check"></i><b>8.2</b> Probability mass functions</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#intuition-1"><i class="fa fa-check"></i><b>8.2.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#definition-3"><i class="fa fa-check"></i><b>8.2.2</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#cumulative-mass-function"><i class="fa fa-check"></i><b>8.3</b> Cumulative mass function</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#three-person-experiment"><i class="fa fa-check"></i><b>8.3.1</b> Three person experiment</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#famous-discrete-random-variables"><i class="fa fa-check"></i><b>8.4</b> Famous discrete random variables</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#bernoulli"><i class="fa fa-check"></i><b>8.4.1</b> Bernoulli</a></li>
<li class="chapter" data-level="8.4.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#binomial"><i class="fa fa-check"></i><b>8.4.2</b> Binomial</a></li>
<li class="chapter" data-level="8.4.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#geometric"><i class="fa fa-check"></i><b>8.4.3</b> Geometric</a></li>
<li class="chapter" data-level="8.4.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#poisson"><i class="fa fa-check"></i><b>8.4.4</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#functions-of-random-variables"><i class="fa fa-check"></i><b>8.5</b> Functions of random variables</a></li>
<li class="chapter" data-level="8.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expectation-mean-and-variance"><i class="fa fa-check"></i><b>8.6</b> Expectation, mean, and variance</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#motivation"><i class="fa fa-check"></i><b>8.6.1</b> Motivation</a></li>
<li class="chapter" data-level="8.6.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expectation"><i class="fa fa-check"></i><b>8.6.2</b> Expectation</a></li>
<li class="chapter" data-level="8.6.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance-moments-and-the-expected-value-rule"><i class="fa fa-check"></i><b>8.6.3</b> Variance, moments, and the expected value rule</a></li>
<li class="chapter" data-level="8.6.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#practice-calculating-expectation-and-variance"><i class="fa fa-check"></i><b>8.6.4</b> Practice calculating expectation and variance</a></li>
<li class="chapter" data-level="8.6.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#decision-making-using-expected-values"><i class="fa fa-check"></i><b>8.6.5</b> Decision making using expected values</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#cumulative-mass-function-redux"><i class="fa fa-check"></i><b>8.7</b> Cumulative mass function, redux</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#common-cmfs"><i class="fa fa-check"></i><b>8.7.1</b> Common CMFs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="general-random-variables.html"><a href="general-random-variables.html"><i class="fa fa-check"></i><b>9</b> General random variables</a>
<ul>
<li class="chapter" data-level="" data-path="general-random-variables.html"><a href="general-random-variables.html#learning-objectives-8"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="general-random-variables.html"><a href="general-random-variables.html#supplemental-readings-8"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="9.1" data-path="general-random-variables.html"><a href="general-random-variables.html#continuous-random-variables"><i class="fa fa-check"></i><b>9.1</b> Continuous random variables</a></li>
<li class="chapter" data-level="9.2" data-path="general-random-variables.html"><a href="general-random-variables.html#probability-density-function"><i class="fa fa-check"></i><b>9.2</b> Probability density function</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="general-random-variables.html"><a href="general-random-variables.html#definition-4"><i class="fa fa-check"></i><b>9.2.1</b> Definition</a></li>
<li class="chapter" data-level="9.2.2" data-path="general-random-variables.html"><a href="general-random-variables.html#example-uniform-random-variable"><i class="fa fa-check"></i><b>9.2.2</b> Example: Uniform Random Variable</a></li>
<li class="chapter" data-level="9.2.3" data-path="general-random-variables.html"><a href="general-random-variables.html#expectation-continuous"><i class="fa fa-check"></i><b>9.2.3</b> Expectation</a></li>
<li class="chapter" data-level="9.2.4" data-path="general-random-variables.html"><a href="general-random-variables.html#exponential-random-variable"><i class="fa fa-check"></i><b>9.2.4</b> Exponential random variable</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="general-random-variables.html"><a href="general-random-variables.html#cumulative-distribution-function"><i class="fa fa-check"></i><b>9.3</b> Cumulative distribution function</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="general-random-variables.html"><a href="general-random-variables.html#properties-of-cdfs"><i class="fa fa-check"></i><b>9.3.1</b> Properties of CDFs</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="general-random-variables.html"><a href="general-random-variables.html#normal-distribution"><i class="fa fa-check"></i><b>9.4</b> Normal distribution</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="general-random-variables.html"><a href="general-random-variables.html#expected-valuevariance-of-normal-distribution"><i class="fa fa-check"></i><b>9.4.1</b> Expected value/variance of normal distribution</a></li>
<li class="chapter" data-level="9.4.2" data-path="general-random-variables.html"><a href="general-random-variables.html#why-rely-on-the-standard-normal-distribution"><i class="fa fa-check"></i><b>9.4.2</b> Why rely on the standard normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="general-random-variables.html"><a href="general-random-variables.html#gamma-distribution"><i class="fa fa-check"></i><b>9.5</b> Gamma distribution</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="general-random-variables.html"><a href="general-random-variables.html#properties-of-gamma-distributions"><i class="fa fa-check"></i><b>9.5.1</b> Properties of Gamma distributions</a></li>
<li class="chapter" data-level="9.5.2" data-path="general-random-variables.html"><a href="general-random-variables.html#importance-of-the-gamma-distribution"><i class="fa fa-check"></i><b>9.5.2</b> Importance of the Gamma distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="general-random-variables.html"><a href="general-random-variables.html#chi2-distribution"><i class="fa fa-check"></i><b>9.6</b> <span class="math inline">\(\chi^2\)</span> distribution</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="general-random-variables.html"><a href="general-random-variables.html#chi2-properties"><i class="fa fa-check"></i><b>9.6.1</b> <span class="math inline">\(\chi^2\)</span> properties</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="general-random-variables.html"><a href="general-random-variables.html#students-t-distribution"><i class="fa fa-check"></i><b>9.7</b> Studentâs <span class="math inline">\(t\)</span> distribution</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="general-random-variables.html"><a href="general-random-variables.html#history-of-students-t"><i class="fa fa-check"></i><b>9.7.1</b> History of Studentâs <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="9.7.2" data-path="general-random-variables.html"><a href="general-random-variables.html#differences-from-the-normal-distribution"><i class="fa fa-check"></i><b>9.7.2</b> Differences from the Normal Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="multivar-distribs.html"><a href="multivar-distribs.html"><i class="fa fa-check"></i><b>10</b> Multivariate distributions</a>
<ul>
<li class="chapter" data-level="" data-path="multivar-distribs.html"><a href="multivar-distribs.html#learning-objectives-9"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="multivar-distribs.html"><a href="multivar-distribs.html#supplemental-readings-9"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="10.1" data-path="multivar-distribs.html"><a href="multivar-distribs.html#multivariate-distribution"><i class="fa fa-check"></i><b>10.1</b> Multivariate distribution</a></li>
<li class="chapter" data-level="10.2" data-path="multivar-distribs.html"><a href="multivar-distribs.html#examples-of-joint-pdfs"><i class="fa fa-check"></i><b>10.2</b> Examples of joint PDFs</a></li>
<li class="chapter" data-level="10.3" data-path="multivar-distribs.html"><a href="multivar-distribs.html#multivariate-cumulative-density-function"><i class="fa fa-check"></i><b>10.3</b> Multivariate cumulative density function</a></li>
<li class="chapter" data-level="10.4" data-path="multivar-distribs.html"><a href="multivar-distribs.html#marginalization"><i class="fa fa-check"></i><b>10.4</b> Marginalization</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="multivar-distribs.html"><a href="multivar-distribs.html#joint-vs.-conditional-pdf"><i class="fa fa-check"></i><b>10.4.1</b> Joint vs.Â conditional PDF</a></li>
<li class="chapter" data-level="10.4.2" data-path="multivar-distribs.html"><a href="multivar-distribs.html#why-does-marginalization-work"><i class="fa fa-check"></i><b>10.4.2</b> Why does marginalization work?</a></li>
<li class="chapter" data-level="10.4.3" data-path="multivar-distribs.html"><a href="multivar-distribs.html#move-to-the-continuous-case"><i class="fa fa-check"></i><b>10.4.3</b> Move to the continuous case</a></li>
<li class="chapter" data-level="10.4.4" data-path="multivar-distribs.html"><a href="multivar-distribs.html#a-simple-example"><i class="fa fa-check"></i><b>10.4.4</b> A (simple) example</a></li>
<li class="chapter" data-level="10.4.5" data-path="multivar-distribs.html"><a href="multivar-distribs.html#more-complex-example"><i class="fa fa-check"></i><b>10.4.5</b> More complex example</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="multivar-distribs.html"><a href="multivar-distribs.html#conditional-distribution"><i class="fa fa-check"></i><b>10.5</b> Conditional distribution</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="multivar-distribs.html"><a href="multivar-distribs.html#a-simple-example-of-dependence"><i class="fa fa-check"></i><b>10.5.1</b> A (simple) example of dependence</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="multivar-distribs.html"><a href="multivar-distribs.html#expectation-1"><i class="fa fa-check"></i><b>10.6</b> Expectation</a></li>
<li class="chapter" data-level="10.7" data-path="multivar-distribs.html"><a href="multivar-distribs.html#covariance-and-correlation"><i class="fa fa-check"></i><b>10.7</b> Covariance and correlation</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="multivar-distribs.html"><a href="multivar-distribs.html#some-observations"><i class="fa fa-check"></i><b>10.7.1</b> Some observations</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="multivar-distribs.html"><a href="multivar-distribs.html#sums-of-random-variables"><i class="fa fa-check"></i><b>10.8</b> Sums of random variables</a></li>
<li class="chapter" data-level="10.9" data-path="multivar-distribs.html"><a href="multivar-distribs.html#multivariate-normal-distribution-1"><i class="fa fa-check"></i><b>10.9</b> Multivariate normal distribution</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="multivar-distribs.html"><a href="multivar-distribs.html#bivariate-example"><i class="fa fa-check"></i><b>10.9.1</b> Bivariate example</a></li>
<li class="chapter" data-level="10.9.2" data-path="multivar-distribs.html"><a href="multivar-distribs.html#properties-of-the-multivariate-normal-distribution"><i class="fa fa-check"></i><b>10.9.2</b> Properties of the multivariate normal distribution</a></li>
<li class="chapter" data-level="10.9.3" data-path="multivar-distribs.html"><a href="multivar-distribs.html#independence-and-multivariate-normal"><i class="fa fa-check"></i><b>10.9.3</b> Independence and multivariate normal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="sequences-derivatives.html"><a href="sequences-derivatives.html#limits"><i class="fa fa-check"></i><b>11</b> Properties of random variables and limit theorems</a>
<ul>
<li class="chapter" data-level="" data-path="limits.html"><a href="limits.html"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="limits.html"><a href="limits.html#supplemental-readings-10"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="11.1" data-path="limits.html"><a href="limits.html#iterated-expectations"><i class="fa fa-check"></i><b>11.1</b> Iterated Expectations</a></li>
<li class="chapter" data-level="11.2" data-path="limits.html"><a href="limits.html#change-of-coordinates"><i class="fa fa-check"></i><b>11.2</b> Change of coordinates</a></li>
<li class="chapter" data-level="11.3" data-path="limits.html"><a href="limits.html#moment-generating-functions"><i class="fa fa-check"></i><b>11.3</b> Moment generating functions</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="limits.html"><a href="limits.html#the-moments-of-the-normal-distribution"><i class="fa fa-check"></i><b>11.3.1</b> The moments of the normal distribution</a></li>
<li class="chapter" data-level="11.3.2" data-path="limits.html"><a href="limits.html#extracting-moments-of-the-normal-distribution"><i class="fa fa-check"></i><b>11.3.2</b> Extracting moments of the normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="limits.html"><a href="limits.html#sequences-of-independent-random-variables"><i class="fa fa-check"></i><b>11.4</b> Sequences of independent random variables</a></li>
<li class="chapter" data-level="11.5" data-path="limits.html"><a href="limits.html#inequalities-and-limit-theorems"><i class="fa fa-check"></i><b>11.5</b> Inequalities and limit theorems</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="limits.html"><a href="limits.html#limit-theorems"><i class="fa fa-check"></i><b>11.5.1</b> Limit theorems</a></li>
<li class="chapter" data-level="11.5.2" data-path="limits.html"><a href="limits.html#weak-law-of-large-numbers"><i class="fa fa-check"></i><b>11.5.2</b> Weak law of large numbers</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="limits.html"><a href="limits.html#sequence-of-random-variables"><i class="fa fa-check"></i><b>11.6</b> Sequence of random variables</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="limits.html"><a href="limits.html#meanvariance-of-sample-mean"><i class="fa fa-check"></i><b>11.6.1</b> Mean/variance of sample mean</a></li>
<li class="chapter" data-level="11.6.2" data-path="limits.html"><a href="limits.html#weak-law-of-large-numbers-1"><i class="fa fa-check"></i><b>11.6.2</b> Weak law of large numbers</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="limits.html"><a href="limits.html#sequences-and-convergence"><i class="fa fa-check"></i><b>11.7</b> Sequences and convergence</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="limits.html"><a href="limits.html#convergence-definitions"><i class="fa fa-check"></i><b>11.7.1</b> Convergence definitions</a></li>
<li class="chapter" data-level="11.7.2" data-path="limits.html"><a href="limits.html#convergence-in-probability"><i class="fa fa-check"></i><b>11.7.2</b> Convergence in probability</a></li>
<li class="chapter" data-level="11.7.3" data-path="limits.html"><a href="limits.html#almost-sure-convergence"><i class="fa fa-check"></i><b>11.7.3</b> Almost sure convergence</a></li>
<li class="chapter" data-level="11.7.4" data-path="limits.html"><a href="limits.html#convergence-in-distribution"><i class="fa fa-check"></i><b>11.7.4</b> Convergence in distribution</a></li>
<li class="chapter" data-level="11.7.5" data-path="limits.html"><a href="limits.html#convergence-in-distribution-not-rightarrow-convergence-in-probability"><i class="fa fa-check"></i><b>11.7.5</b> Convergence in distribution <span class="math inline">\(\not \Rightarrow\)</span> convergence in probability</a></li>
<li class="chapter" data-level="11.7.6" data-path="limits.html"><a href="limits.html#central-limit-theorem"><i class="fa fa-check"></i><b>11.7.6</b> Central limit theorem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="classic-inference.html"><a href="classic-inference.html"><i class="fa fa-check"></i><b>12</b> Classical statistical inference</a>
<ul>
<li class="chapter" data-level="" data-path="classic-inference.html"><a href="classic-inference.html#learning-objectives-11"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="classic-inference.html"><a href="classic-inference.html#supplemental-readings-11"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="12.1" data-path="classic-inference.html"><a href="classic-inference.html#statistical-inference"><i class="fa fa-check"></i><b>12.1</b> Statistical inference</a></li>
<li class="chapter" data-level="12.2" data-path="classic-inference.html"><a href="classic-inference.html#parametric-models"><i class="fa fa-check"></i><b>12.2</b> Parametric models</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="classic-inference.html"><a href="classic-inference.html#examples-of-parametric-models"><i class="fa fa-check"></i><b>12.2.1</b> Examples of parametric models</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="classic-inference.html"><a href="classic-inference.html#point-estimates"><i class="fa fa-check"></i><b>12.3</b> Point estimates</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="classic-inference.html"><a href="classic-inference.html#properties-of-point-estimates"><i class="fa fa-check"></i><b>12.3.1</b> Properties of point estimates</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="classic-inference.html"><a href="classic-inference.html#confidence-sets"><i class="fa fa-check"></i><b>12.4</b> Confidence sets</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="classic-inference.html"><a href="classic-inference.html#caution-interpreting-confidence-intervals"><i class="fa fa-check"></i><b>12.4.1</b> Caution interpreting confidence intervals</a></li>
<li class="chapter" data-level="12.4.2" data-path="classic-inference.html"><a href="classic-inference.html#constructing-confidence-intervals"><i class="fa fa-check"></i><b>12.4.2</b> Constructing confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="classic-inference.html"><a href="classic-inference.html#hypothesis-testing"><i class="fa fa-check"></i><b>12.5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="classic-inference.html"><a href="classic-inference.html#types-of-errors"><i class="fa fa-check"></i><b>12.5.1</b> Types of errors</a></li>
<li class="chapter" data-level="12.5.2" data-path="classic-inference.html"><a href="classic-inference.html#power-function"><i class="fa fa-check"></i><b>12.5.2</b> Power function</a></li>
<li class="chapter" data-level="12.5.3" data-path="classic-inference.html"><a href="classic-inference.html#sided-tests"><i class="fa fa-check"></i><b>12.5.3</b> Sided tests</a></li>
<li class="chapter" data-level="12.5.4" data-path="classic-inference.html"><a href="classic-inference.html#example-hypothesis-test"><i class="fa fa-check"></i><b>12.5.4</b> Example hypothesis test</a></li>
<li class="chapter" data-level="12.5.5" data-path="classic-inference.html"><a href="classic-inference.html#wald-test"><i class="fa fa-check"></i><b>12.5.5</b> Wald test</a></li>
<li class="chapter" data-level="12.5.6" data-path="classic-inference.html"><a href="classic-inference.html#wald-or-t-test"><i class="fa fa-check"></i><b>12.5.6</b> Wald or <span class="math inline">\(t\)</span>-test?</a></li>
<li class="chapter" data-level="12.5.7" data-path="classic-inference.html"><a href="classic-inference.html#relationship-to-confidence-intervals"><i class="fa fa-check"></i><b>12.5.7</b> Relationship to confidence intervals</a></li>
<li class="chapter" data-level="12.5.8" data-path="classic-inference.html"><a href="classic-inference.html#statistical-vs.-scientific-significance"><i class="fa fa-check"></i><b>12.5.8</b> Statistical vs.Â scientific significance</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="classic-inference.html"><a href="classic-inference.html#p-values"><i class="fa fa-check"></i><b>12.6</b> <span class="math inline">\(p\)</span>-values</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="classic-inference.html"><a href="classic-inference.html#interpreting-p-values"><i class="fa fa-check"></i><b>12.6.1</b> Interpreting <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="12.6.2" data-path="classic-inference.html"><a href="classic-inference.html#calculating-p-values"><i class="fa fa-check"></i><b>12.6.2</b> Calculating <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="12.6.3" data-path="classic-inference.html"><a href="classic-inference.html#pearsons-chi2-test-for-multinomial-data"><i class="fa fa-check"></i><b>12.6.3</b> Pearsonâs <span class="math inline">\(\chi^2\)</span> test for multinomial data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="mle-ols.html"><a href="mle-ols.html"><i class="fa fa-check"></i><b>13</b> Maximum likelihood estimation and linear regression</a>
<ul>
<li class="chapter" data-level="" data-path="mle-ols.html"><a href="mle-ols.html#learning-objectives-12"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="mle-ols.html"><a href="mle-ols.html#supplemental-readings-12"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="13.1" data-path="mle-ols.html"><a href="mle-ols.html#maximum-likelihood"><i class="fa fa-check"></i><b>13.1</b> Maximum likelihood</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="mle-ols.html"><a href="mle-ols.html#properties-of-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>13.1.1</b> Properties of maximum likelihood estimators</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="mle-ols.html"><a href="mle-ols.html#least-squares-regression"><i class="fa fa-check"></i><b>13.2</b> Least squares regression</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="mle-ols.html"><a href="mle-ols.html#simple-linear-regression"><i class="fa fa-check"></i><b>13.2.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="13.2.2" data-path="mle-ols.html"><a href="mle-ols.html#estimation-strategy"><i class="fa fa-check"></i><b>13.2.2</b> Estimation strategy</a></li>
<li class="chapter" data-level="13.2.3" data-path="mle-ols.html"><a href="mle-ols.html#least-squares-estimator"><i class="fa fa-check"></i><b>13.2.3</b> Least squares estimator</a></li>
<li class="chapter" data-level="13.2.4" data-path="mle-ols.html"><a href="mle-ols.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>13.2.4</b> Maximum likelihood estimation</a></li>
<li class="chapter" data-level="13.2.5" data-path="mle-ols.html"><a href="mle-ols.html#properties-of-the-least-squares-estimator"><i class="fa fa-check"></i><b>13.2.5</b> Properties of the least squares estimator</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="mle-ols.html"><a href="mle-ols.html#assumptions-of-linear-regression-models"><i class="fa fa-check"></i><b>13.3</b> Assumptions of linear regression models</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="mle-ols.html"><a href="mle-ols.html#linearity"><i class="fa fa-check"></i><b>13.3.1</b> Linearity</a></li>
<li class="chapter" data-level="13.3.2" data-path="mle-ols.html"><a href="mle-ols.html#constant-variance"><i class="fa fa-check"></i><b>13.3.2</b> Constant variance</a></li>
<li class="chapter" data-level="13.3.3" data-path="mle-ols.html"><a href="mle-ols.html#normality"><i class="fa fa-check"></i><b>13.3.3</b> Normality</a></li>
<li class="chapter" data-level="13.3.4" data-path="mle-ols.html"><a href="mle-ols.html#independence"><i class="fa fa-check"></i><b>13.3.4</b> Independence</a></li>
<li class="chapter" data-level="13.3.5" data-path="mle-ols.html"><a href="mle-ols.html#fixed-x-or-x-measured-without-error-and-independent-of-the-error"><i class="fa fa-check"></i><b>13.3.5</b> Fixed <span class="math inline">\(X\)</span>, or <span class="math inline">\(X\)</span> measured without error and independent of the error</a></li>
<li class="chapter" data-level="13.3.6" data-path="mle-ols.html"><a href="mle-ols.html#x-is-not-invariant"><i class="fa fa-check"></i><b>13.3.6</b> <span class="math inline">\(X\)</span> is not invariant</a></li>
<li class="chapter" data-level="13.3.7" data-path="mle-ols.html"><a href="mle-ols.html#handling-violations-of-assumptions"><i class="fa fa-check"></i><b>13.3.7</b> Handling violations of assumptions</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="mle-ols.html"><a href="mle-ols.html#unusual-and-influential-data"><i class="fa fa-check"></i><b>13.4</b> Unusual and influential data</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="mle-ols.html"><a href="mle-ols.html#terms"><i class="fa fa-check"></i><b>13.4.1</b> Terms</a></li>
<li class="chapter" data-level="13.4.2" data-path="mle-ols.html"><a href="mle-ols.html#measuring-leverage"><i class="fa fa-check"></i><b>13.4.2</b> Measuring leverage</a></li>
<li class="chapter" data-level="13.4.3" data-path="mle-ols.html"><a href="mle-ols.html#measuring-discrepancy"><i class="fa fa-check"></i><b>13.4.3</b> Measuring discrepancy</a></li>
<li class="chapter" data-level="13.4.4" data-path="mle-ols.html"><a href="mle-ols.html#measuring-influence"><i class="fa fa-check"></i><b>13.4.4</b> Measuring influence</a></li>
<li class="chapter" data-level="13.4.5" data-path="mle-ols.html"><a href="mle-ols.html#visualizing-leverage-discrepancy-and-influence"><i class="fa fa-check"></i><b>13.4.5</b> Visualizing leverage, discrepancy, and influence</a></li>
<li class="chapter" data-level="13.4.6" data-path="mle-ols.html"><a href="mle-ols.html#numerical-rules-of-thumb"><i class="fa fa-check"></i><b>13.4.6</b> Numerical rules of thumb</a></li>
<li class="chapter" data-level="13.4.7" data-path="mle-ols.html"><a href="mle-ols.html#how-to-treat-unusual-observations"><i class="fa fa-check"></i><b>13.4.7</b> How to treat unusual observations</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="mle-ols.html"><a href="mle-ols.html#non-normally-distributed-errors"><i class="fa fa-check"></i><b>13.5</b> Non-normally distributed errors</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="mle-ols.html"><a href="mle-ols.html#detecting-non-normally-distributed-errors"><i class="fa fa-check"></i><b>13.5.1</b> Detecting non-normally distributed errors</a></li>
<li class="chapter" data-level="13.5.2" data-path="mle-ols.html"><a href="mle-ols.html#fixing-non-normally-distributed-errors"><i class="fa fa-check"></i><b>13.5.2</b> Fixing non-normally distributed errors</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="mle-ols.html"><a href="mle-ols.html#non-constant-error-variance"><i class="fa fa-check"></i><b>13.6</b> Non-constant error variance</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="mle-ols.html"><a href="mle-ols.html#detecting-heteroscedasticity"><i class="fa fa-check"></i><b>13.6.1</b> Detecting heteroscedasticity</a></li>
<li class="chapter" data-level="13.6.2" data-path="mle-ols.html"><a href="mle-ols.html#accounting-for-heteroscedasticity"><i class="fa fa-check"></i><b>13.6.2</b> Accounting for heteroscedasticity</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="mle-ols.html"><a href="mle-ols.html#non-linearity-in-the-data"><i class="fa fa-check"></i><b>13.7</b> Non-linearity in the data</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="mle-ols.html"><a href="mle-ols.html#partial-residual-plots"><i class="fa fa-check"></i><b>13.7.1</b> Partial residual plots</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="mle-ols.html"><a href="mle-ols.html#collinearity"><i class="fa fa-check"></i><b>13.8</b> Collinearity</a>
<ul>
<li class="chapter" data-level="13.8.1" data-path="mle-ols.html"><a href="mle-ols.html#perfect-collinearity"><i class="fa fa-check"></i><b>13.8.1</b> Perfect collinearity</a></li>
<li class="chapter" data-level="13.8.2" data-path="mle-ols.html"><a href="mle-ols.html#less-than-perfect-collinearity"><i class="fa fa-check"></i><b>13.8.2</b> Less-than-perfect collinearity</a></li>
<li class="chapter" data-level="13.8.3" data-path="mle-ols.html"><a href="mle-ols.html#fixing-multicollinearity"><i class="fa fa-check"></i><b>13.8.3</b> Fixing multicollinearity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>14</b> Bayesian inference</a>
<ul>
<li class="chapter" data-level="" data-path="bayesian-inference.html"><a href="bayesian-inference.html#learning-objectives-13"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="bayesian-inference.html"><a href="bayesian-inference.html#supplemental-readings-13"><i class="fa fa-check"></i>Supplemental readings</a></li>
<li class="chapter" data-level="14.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#bayesian-philosophy"><i class="fa fa-check"></i><b>14.1</b> Bayesian philosophy</a></li>
<li class="chapter" data-level="14.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#bayes-theorem"><i class="fa fa-check"></i><b>14.2</b> Bayesâ theorem</a></li>
<li class="chapter" data-level="14.3" data-path="bayesian-inference.html"><a href="bayesian-inference.html#bayesian-method"><i class="fa fa-check"></i><b>14.3</b> Bayesian method</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#example-coin-tossing"><i class="fa fa-check"></i><b>14.3.1</b> Example: coin tossing</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="bayesian-inference.html"><a href="bayesian-inference.html#updating-your-prior-beliefs"><i class="fa fa-check"></i><b>14.4</b> Updating your prior beliefs</a></li>
<li class="chapter" data-level="14.5" data-path="bayesian-inference.html"><a href="bayesian-inference.html#simulation"><i class="fa fa-check"></i><b>14.5</b> Simulation</a></li>
<li class="chapter" data-level="14.6" data-path="bayesian-inference.html"><a href="bayesian-inference.html#priors"><i class="fa fa-check"></i><b>14.6</b> Priors</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#improper-priors"><i class="fa fa-check"></i><b>14.6.1</b> Improper priors</a></li>
<li class="chapter" data-level="14.6.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#flat-priors-are-not-invariant"><i class="fa fa-check"></i><b>14.6.2</b> Flat priors are not invariant</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="bayesian-inference.html"><a href="bayesian-inference.html#multiparameter-problems"><i class="fa fa-check"></i><b>14.7</b> Multiparameter problems</a></li>
<li class="chapter" data-level="14.8" data-path="bayesian-inference.html"><a href="bayesian-inference.html#critiques-and-defenses-of-bayesian-inference"><i class="fa fa-check"></i><b>14.8</b> Critiques and defenses of Bayesian inference</a>
<ul>
<li class="chapter" data-level="14.8.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#critique-of-bayesian-inference"><i class="fa fa-check"></i><b>14.8.1</b> Critique of Bayesian inference</a></li>
<li class="chapter" data-level="14.8.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#defense-of-bayesian-inference"><i class="fa fa-check"></i><b>14.8.2</b> Defense of Bayesian inference</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bayesian-inference.html"><a href="bayesian-inference.html#acknowledgements-1"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Math Camp</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classic-inference" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Lecture 12</span> Classical statistical inference<a href="classic-inference.html#classic-inference" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="learning-objectives-11" class="section level2 unnumbered hasAnchor">
<h2>Learning objectives<a href="classic-inference.html#learning-objectives-11" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Define classical statistical inference</li>
<li>Summarize core concepts of point estimates, confidence sets, and hypothesis testing</li>
<li>Define parametric inference and identify use cases</li>
<li>Summarize point estimates</li>
<li>Define hypothesis testing and <span class="math inline">\(p\)</span>-value</li>
<li>Define the Wald test</li>
<li>Summarize the <span class="math inline">\(\chi^2\)</span> test of significance</li>
</ul>
</div>
<div id="supplemental-readings-11" class="section level2 unnumbered hasAnchor">
<h2>Supplemental readings<a href="classic-inference.html#supplemental-readings-11" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Chapter 9 <span class="citation">Bertsekas and Tsitsiklis (<a href="#ref-bertsekas2008" role="doc-biblioref">2008</a>)</span></li>
<li><span class="citation">Wasserman (<a href="#ref-wasserman2013" role="doc-biblioref">2013</a>)</span>
<ul>
<li><a href="https://link-springer-com.proxy.uchicago.edu/content/pdf/10.1007%2F978-0-387-21736-9_6.pdf">Ch 6 - Models, Statistical Inference and Learning</a></li>
<li><a href="https://link-springer-com.proxy.uchicago.edu/content/pdf/10.1007%2F978-0-387-21736-9_10.pdf">Ch 10 - Hypothesis Testing and p-values</a></li>
</ul></li>
</ul>
</div>
<div id="statistical-inference" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Statistical inference<a href="classic-inference.html#statistical-inference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Statistical inference</strong> is the process of using data to infer the probability distribution/random variable that generated the data. Given a sample <span class="math inline">\(X_1, \ldots, X_n \sim F\)</span>, how do we infer <span class="math inline">\(F\)</span>? Sometimes we want to infer all the features/parameters of <span class="math inline">\(F\)</span>, and sometimes we only need a subset of those features/parameters.</p>
</div>
<div id="parametric-models" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Parametric models<a href="classic-inference.html#parametric-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>statistical model</strong> <span class="math inline">\(\xi\)</span> is a set of distributions (or densities or regression functions). A <strong>parametric model</strong> is a set <span class="math inline">\(\xi\)</span> that can be parameterized by a finite number of parameters. We have seen many examples of parametric models - all the major types of random variables weâve explored are defined in terms of a fixed number of parameters. For instance, if we assume that the data is generated by a Normal distribution, then the model is</p>
<p><span class="math display">\[\xi \equiv f(x; \mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}} \exp \left[ -\frac{1}{2\sigma^2} (x - \mu)^2 \right], \quad \mu \in \Re, \sigma &gt; 0\]</span></p>
<p>This is an example of a two-parameter model. The density <span class="math inline">\(f(x; \mu, \sigma)\)</span> indicates that <span class="math inline">\(x\)</span> is a value of the random variable <span class="math inline">\(X\)</span>, whereas <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are parameters that define the model.</p>
<p>In general, a <strong>parametric model</strong> takes the form</p>
<p><span class="math display">\[\xi \equiv f(x; \theta) : \theta \in \Theta\]</span></p>
<p>where <span class="math inline">\(\theta\)</span> is an unknown parameter (or vector of parameters) that can only take values in the parameter space <span class="math inline">\(\Theta\)</span>. If <span class="math inline">\(\theta\)</span> is a vector but we are only interested in one component of <span class="math inline">\(\theta\)</span>, then we call the remaining parameters <strong>nuisance parameters</strong>.</p>
<div id="examples-of-parametric-models" class="section level3 hasAnchor" number="12.2.1">
<h3><span class="header-section-number">12.2.1</span> Examples of parametric models<a href="classic-inference.html#examples-of-parametric-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="example">
<p><span id="exm:unlabeled-div-187" class="example"><strong>Example 12.1  (One-dimensional parametric estimation) </strong></span>Let <span class="math inline">\(X_1, \ldots, X_n\)</span> be independent observations drawn from a Bernoulli random variable with probability <span class="math inline">\(\pi\)</span> of success. The problem is to estimate the parameter <span class="math inline">\(\pi\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-188" class="example"><strong>Example 12.2  (Two-dimensional parametric estimation) </strong></span>Suppose that <span class="math inline">\(X_1, \ldots, X_n \sim F\)</span> and we assume that the PDF <span class="math inline">\(f \in \xi\)</span> where</p>
<p><span class="math display">\[\xi \equiv f(x; \mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}} \exp \left[ -\frac{1}{2\sigma^2} (x - \mu)^2 \right], \quad \mu \in \Re, \sigma &gt; 0\]</span></p>
<p>In this case, there are two parameters, <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. The goal is to estimate the parameters from the data. If we are only interested in estimating <span class="math inline">\(\mu\)</span> (which is generally the case for inferential methods such as <a href="mle-ols.html#least-squares-regression">linear regression</a>), then <span class="math inline">\(\mu\)</span> is the parameter of interest and <span class="math inline">\(\sigma\)</span> is a nuisance parameter.</p>
</div>
</div>
</div>
<div id="point-estimates" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> Point estimates<a href="classic-inference.html#point-estimates" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Point estimation</strong> refers to providing a single âbest guessâ of some quantity of interest. This quantity of interest could be a parameter in a parametric model, a CDF <span class="math inline">\(F\)</span>, a PDF <span class="math inline">\(f\)</span>, a regression function <span class="math inline">\(r\)</span>, or a prediction for a future value <span class="math inline">\(Y\)</span> of some random variable.</p>
<p>We denote a point estimate of <span class="math inline">\(\theta\)</span> by <span class="math inline">\(\hat{\theta}\)</span> or <span class="math inline">\(\hat{\theta}_n\)</span>. Remember that <span class="math inline">\(\theta\)</span> is a fixed, unknown quantity. The estimate <span class="math inline">\(\hat{\theta}\)</span> depends on the data, so <span class="math inline">\(\hat{\theta}\)</span> is a random variable. More formally, let <span class="math inline">\(X_1, \ldots, X_n\)</span> be <span class="math inline">\(n\)</span> IID (independently and identically drawn) data points from some distribution <span class="math inline">\(F\)</span>. A point estimator <span class="math inline">\(\hat{\theta}_n\)</span> of a parameter <span class="math inline">\(\theta\)</span> is some function of <span class="math inline">\(X_1, \ldots, X_n\)</span>:</p>
<p><span class="math display">\[\hat{\theta}_n = g(X_1, \ldots, X_n)\]</span></p>
<div id="properties-of-point-estimates" class="section level3 hasAnchor" number="12.3.1">
<h3><span class="header-section-number">12.3.1</span> Properties of point estimates<a href="classic-inference.html#properties-of-point-estimates" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>bias</strong> of an estimator is defined as</p>
<p><span class="math display">\[\text{bias}(\hat{\theta}_n) = \E_\theta (\hat{\theta_n}) - \theta\]</span></p>
<p>When <span class="math inline">\(\E (\hat{\theta_n}) - \theta = 0\)</span>, we say that <span class="math inline">\(\hat{\theta_n}\)</span> is <strong>unbiased</strong>. Many estimators in statistical inference are not unbiased â with modern approaches, this is sometimes justified. We will see examples of this in Perspectives on Computational Modeling. A more preferable requirement for an estimator is <strong>consistency</strong>: as the number of observations <span class="math inline">\(n\)</span> increases, the estimator should converge towards the true parameter <span class="math inline">\(\theta\)</span>.</p>
<p>The distribution of <span class="math inline">\(\hat{\theta}_n\)</span> is called the <strong>sampling distribution</strong>. The standard deviation of <span class="math inline">\(\hat{\theta}_n\)</span> is called the standard error:</p>
<p><span class="math display">\[\se = \sd(\hat{\theta}_n) = \sqrt{\Var (\hat{\theta}_n)}\]</span></p>
<p>Frequently the standard error depends on the unknown <span class="math inline">\(F\)</span>. In those cases, we usually estimate it. The estimated standard error is denoted by <span class="math inline">\(\widehat{\se}\)</span>.</p>
<p>The quality of the point estimate is sometimes assessed by the <strong>mean squared error</strong> (MSE) defined by</p>
<p><span class="math display">\[
\begin{align}
\text{MSE} &amp;= \E_\theta [(\hat{\theta}_n - \theta)^2] \\
&amp;= \text{bias}^2(\hat{\theta}_n) + \Var_\theta (\hat{\theta}_n)
\end{align}
\]</span></p>

<div class="rmdnote">
<p>Remember that <span class="math inline">\(\E_\theta (\cdot)\)</span> refers to expectation with respect to the distribution <span class="math inline">\(f(x_1, \ldots, x_n; \theta)\)</span> that generated the data. <span class="math inline">\(\theta\)</span> does not have a distribution - it is a fixed, but unknown, value.</p>
</div>
<p>Many estimators turn out to have, approximately, a Normal distribution â another reason why this continuous distribution is so important to statistical inference.</p>
<p><span class="math display">\[\frac{\hat{\theta}_n - \theta}{\se} \leadsto N(0,1)\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-189" class="example"><strong>Example 12.3  (Bernoulli distributed random variable) </strong></span>Let <span class="math inline">\(X_1, \ldots, X_n ~ \text{Bernoulli}(\pi)\)</span> and let <span class="math inline">\(\hat{\pi}_n = \frac{1}{n} \sum_{i=1}^n X_i\)</span>. Then</p>
<p><span class="math display">\[\E(\hat{\pi}_n) = \frac{1}{n} \sum_{i=1}^n \E(X_i) = \pi\]</span></p>
<p>so <span class="math inline">\(\hat{\pi}_n\)</span> is unbiased. The standard error is</p>
<p><span class="math display">\[\se = \sqrt{\Var (\hat{\pi}_n)} = \sqrt{\frac{\pi (1 - \pi)}{n}}\]</span></p>
<p>which can be estimated as</p>
<p><span class="math display">\[\widehat{\se} = \sqrt{\frac{\hat{\pi} (1 - \hat{\pi})}{n}}\]</span></p>
<p>Additionally, we have that <span class="math inline">\(\E_\pi (\hat{\pi}_n) = \pi\)</span> so <span class="math inline">\(\text{bias} = \pi - \pi = 0\)</span></p>
<p><span class="math display">\[
\begin{align}
\text{bias}(\hat{\pi}_n) &amp;= \E_\pi (\hat{\pi}) - \pi \\
&amp;= \pi - \pi \\
&amp;= 0
\end{align}
\]</span></p>
<p>and</p>
<p><span class="math display">\[\se = \sqrt{\frac{\pi (1 - \pi)}{n}} \rightarrow 0\]</span></p>
<p>as <span class="math inline">\(n\)</span> increases. Hence, <span class="math inline">\(\hat{\pi}_n\)</span> is a consistent estimator of <span class="math inline">\(\pi\)</span>.</p>
</div>
</div>
</div>
<div id="confidence-sets" class="section level2 hasAnchor" number="12.4">
<h2><span class="header-section-number">12.4</span> Confidence sets<a href="classic-inference.html#confidence-sets" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <span class="math inline">\(1 - \alpha\)</span> <strong>confidence interval</strong> for a parameter <span class="math inline">\(\theta\)</span> is an interval <span class="math inline">\(C_n = (a,b)\)</span> where <span class="math inline">\(a = a(X_1, \ldots, X_n)\)</span> and <span class="math inline">\(b = b(X_1, \ldots, X_n)\)</span> are functions of the data such that</p>
<p><span class="math display">\[\Pr_{\theta} (\theta \in C_n) \geq 1 - \alpha, \quad \forall \, \theta \in \Theta\]</span></p>
<p>In other words, <span class="math inline">\((a,b)\)</span> traps <span class="math inline">\(\theta\)</span> with probability <span class="math inline">\(1- \alpha\)</span>. We call <span class="math inline">\(1 - \alpha\)</span> the <strong>coverage</strong> of the confidence interval.</p>
<div id="caution-interpreting-confidence-intervals" class="section level3 hasAnchor" number="12.4.1">
<h3><span class="header-section-number">12.4.1</span> Caution interpreting confidence intervals<a href="classic-inference.html#caution-interpreting-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math inline">\(C_n\)</span> is random and <span class="math inline">\(\theta\)</span> is fixed. This is a core assumption of statistical inference and especially critical for frequentist inference. Commonly people use 95% confidence intervals corresponding to <span class="math inline">\(\alpha = 0.05\)</span>. If <span class="math inline">\(\theta\)</span> is a vector then we use a <strong>confidence set</strong> (such as a sphere or an ellipse) instead of an interval.</p>
<p>A confidence interval is not a probability statement about <span class="math inline">\(\theta\)</span> since <span class="math inline">\(\theta\)</span> is a fixed quantity, not a random variable. Either <span class="math inline">\(\theta\)</span> is or is not in the interval with probability <span class="math inline">\(1\)</span>. A better definition is:</p>
<div class="definition">
<p><span id="def:unlabeled-div-190" class="definition"><strong>Definition 12.1  (Confidence interval) </strong></span>On day 1, you collect data and construct a 95% confidence interval for a parameter <span class="math inline">\(\theta_1\)</span>. On day 2, you collect new data and construct a 95% confidence interval for a parameter <span class="math inline">\(\theta_2\)</span>. You continue this way constructing confidence intervals for a sequence of unrelated parameters <span class="math inline">\(\theta_1, \theta_2, \ldots\)</span>. Then 95% of your intervals will trap the true parameter value.</p>
</div>
</div>
<div id="constructing-confidence-intervals" class="section level3 hasAnchor" number="12.4.2">
<h3><span class="header-section-number">12.4.2</span> Constructing confidence intervals<a href="classic-inference.html#constructing-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Because point estimators have an approximate Normal distribution, we can use the Normal distribution to construct confidence intervals relatively easily for point estimates by relying directly on the Normal distribution.</p>
<p>Suppose that <span class="math inline">\(\hat{\theta}_n \approx N(\theta, \widehat{\se}^2)\)</span>. Let <span class="math inline">\(\Phi\)</span> be the CDF of a standard Normal distribution and let</p>
<p><span class="math display">\[z_{\frac{\alpha}{2}} = \Phi^{-1} \left(1 - \frac{\alpha}{2} \right)\]</span></p>
<p>That is,</p>
<p><span class="math display">\[\Pr (Z &gt; \frac{\alpha}{2}) = \frac{\alpha}{2}\]</span></p>
<p>and</p>
<p><span class="math display">\[\Pr (-z_{\frac{\alpha}{2}} \leq Z \leq z_{\frac{\alpha}{2}}) = 1 - \alpha\]</span></p>
<p>where <span class="math inline">\(Z \sim N(0,1)\)</span>. Let</p>
<p><span class="math display">\[C_n = (\hat{\theta}_n - z_{\frac{\alpha}{2}} \widehat{\se}, \hat{\theta}_n + z_{\frac{\alpha}{2}} \widehat{\se})\]</span></p>
<p>Then</p>
<p><span class="math display">\[
\begin{align}
\Pr_\theta (\theta \in C_n) &amp;= \Pr_\theta (\hat{\theta}_n - z_{\frac{\alpha}{2}} \widehat{\se} &lt; \theta &lt; \hat{\theta}_n + z_{\frac{\alpha}{2}} \widehat{\se}) \\
&amp;= \Pr_\theta (- z_{\frac{\alpha}{2}} &lt; \frac{\hat{\theta}_n - \theta}{\widehat{\se}} &lt; z_{\frac{\alpha}{2}}) \\
&amp;\rightarrow \Pr ( - z_{\frac{\alpha}{2}} &lt; Z &lt; z_{\frac{\alpha}{2}}) \\
&amp;= 1 - \alpha
\end{align}
\]</span></p>
<p>For 95% confidence intervals, <span class="math inline">\(\alpha = 0.05\)</span> and <span class="math inline">\(z_{\frac{\alpha}{2}} = 1.96 \approx 2\)</span> leading to the approximate 95% confidence interval <span class="math inline">\(\hat{\theta}_n \pm 2 \widehat{\se}\)</span>.</p>
</div>
</div>
<div id="hypothesis-testing" class="section level2 hasAnchor" number="12.5">
<h2><span class="header-section-number">12.5</span> Hypothesis testing<a href="classic-inference.html#hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In <strong>hypothesis testing</strong>, we start with some default theory â called a <strong>null hypothesis</strong> â and we ask if the data provide sufficient evidence to reject the theory. If not, we fail to reject the null hypothesis.</p>
<p>Formally, suppose we partition the parameter space <span class="math inline">\(\Theta\)</span> into two disjoint sets <span class="math inline">\(\Theta_0\)</span> and <span class="math inline">\(\Theta_1\)</span> and that we wish to test</p>
<p><span class="math display">\[H_0: \theta \in \Theta_0 \quad \text{versus} \quad H_1: \theta \in \Theta_1\]</span></p>
<ul>
<li><span class="math inline">\(H_0\)</span> - null hypothesis</li>
<li><span class="math inline">\(H_1\)</span> - alternative hypothesis</li>
</ul>
<p>Let <span class="math inline">\(X\)</span> be a random variable and let <span class="math inline">\(\chi\)</span> be the range of <span class="math inline">\(X\)</span>. We test a hypothesis by finding an appropriate subset of outcomes <span class="math inline">\(R \subset \chi\)</span> called the <strong>rejection region</strong>. If <span class="math inline">\(X \subset R\)</span> we reject the null hypothesis, otherwise we do not reject the null hypothesis. Usually the rejection region <span class="math inline">\(R\)</span> is of the form</p>
<p><span class="math display">\[R = \left\{ x: T(x) &gt; c \right\}\]</span></p>
<p>where <span class="math inline">\(T\)</span> is a <strong>test statistic</strong> and <span class="math inline">\(c\)</span> is a <strong>critical value</strong>. Hypothesis testing requires us to find an appropriate test statistic <span class="math inline">\(T\)</span> and an appropriate critical value <span class="math inline">\(c\)</span> to test a given hypothesis. Different hypotheses require different test statistics.</p>
<div id="types-of-errors" class="section level3 hasAnchor" number="12.5.1">
<h3><span class="header-section-number">12.5.1</span> Types of errors<a href="classic-inference.html#types-of-errors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:type-1-2-error"></span>
<img src="https://2378nh2nfow32gm3mb25krmuyy-wpengine.netdna-ssl.com/wp-content/uploads/2014/05/Type-I-and-II-errors1-625x468.jpg" alt="Stereotypical example of hypothesis testing errors." width="90%" />
<p class="caption">
Figure 12.1: Stereotypical example of hypothesis testing errors.
</p>
</div>
<p>Hypothesis testing is not error-proof. We start from the assumption that <span class="math inline">\(H_0\)</span> is true unless there is strong evidence to reject <span class="math inline">\(H_0\)</span>. Rejecting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is true is a <strong>type I error</strong> (<strong>false positive</strong>), while retaining <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_1\)</span> is true is called a <strong>type II error</strong> (<strong>false negative</strong>).</p>
</div>
<div id="power-function" class="section level3 hasAnchor" number="12.5.2">
<h3><span class="header-section-number">12.5.2</span> Power function<a href="classic-inference.html#power-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>power function</strong> of a test with rejection region <span class="math inline">\(R\)</span> is defined by</p>
<p><span class="math display">\[\beta(\theta) = \Pr_\theta (X \in R)\]</span></p>
<p>The size of a test is defined to be</p>
<p><span class="math display">\[\alpha = \text{sup}_{\theta \in \Theta_0} \beta(\theta)\]</span></p>

<div class="rmdnote">
<span class="math inline">\(\text{sup}\)</span> - <strong>supremum</strong>, or the largest value that <span class="math inline">\(\beta(\theta)\)</span> could take on in the given <span class="math inline">\(\theta \in \Theta_0\)</span>.
</div>
<p>A test is said to have <strong>level</strong> <span class="math inline">\(\alpha\)</span> if its size is less than or equal to <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div id="sided-tests" class="section level3 hasAnchor" number="12.5.3">
<h3><span class="header-section-number">12.5.3</span> Sided tests<a href="classic-inference.html#sided-tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A test of the form</p>
<p><span class="math display">\[H_0: \theta = \theta_0 \quad \text{versus} \quad H_1: \theta \neq \theta_0\]</span></p>
<p>is called a <strong>two-sided test</strong>, or a simple hypothesis. A test of the form</p>
<p><span class="math display">\[H_0: \theta \leq \theta_0 \quad \text{versus} \quad H_1: \theta &gt; \theta_0\]</span></p>
<p>or</p>
<p><span class="math display">\[H_0: \theta \geq \theta_0 \quad \text{versus} \quad H_1: \theta &lt; \theta_0\]</span></p>
<p>is called a <strong>one-sided test</strong>, or a composite hypothesis.</p>
</div>
<div id="example-hypothesis-test" class="section level3 hasAnchor" number="12.5.4">
<h3><span class="header-section-number">12.5.4</span> Example hypothesis test<a href="classic-inference.html#example-hypothesis-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(X_1, \ldots, X_n \sim N(\mu, \sigma^2)\)</span> where <span class="math inline">\(\sigma\)</span> is known. We want to test <span class="math inline">\(H_0: \mu \leq 0\)</span> versus <span class="math inline">\(H_1: \mu &gt; 0\)</span>. Hence, <span class="math inline">\(\Theta_0 = (-\infty, 0]\)</span> and <span class="math inline">\(\Theta_1 = (0, \infty]\)</span>. Consider the test</p>
<p><span class="math display">\[\text{reject } H_0 \text{ if } T&gt;c\]</span></p>
<p>where <span class="math inline">\(T = \bar{X}\)</span>. The rejection region is</p>
<p><span class="math display">\[R = \left\{(x_1, \ldots, x_n): T(x_1, \ldots, x_n) &gt; c \right\}\]</span></p>
<p>Let <span class="math inline">\(Z\)</span> denote the standard Normal random variable. The power function is</p>
<p><span class="math display">\[
\begin{align}
\beta(\mu) &amp;= \Pr_\mu (\bar{X} &gt; c) \\
&amp;= \Pr_\mu \left(\frac{\sqrt{n} (\bar{X} - \mu)}{\sigma} &gt; \frac{\sqrt{n} (c - \mu)}{\sigma} \right) \\
&amp;= \Pr_\mu \left(Z &gt; \frac{\sqrt{n} (c - \mu)}{\sigma} \right) \\
&amp;= 1 - \Phi \left( \frac{\sqrt{n} (c - \mu)}{\sigma} \right)
\end{align}
\]</span></p>
<p>This function is increasing in <span class="math inline">\(\mu\)</span>:</p>
<p><img src="12-frequentist-inference_files/figure-html/normal-cdf-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Hence</p>
<p><span class="math display">\[\alpha = \text{sup}_{\mu \leq 0} \beta(\mu) = \beta(0) = 1 - \Phi \left( \frac{\sqrt{n} (c)}{\sigma} \right)\]</span></p>
<p>For a size <span class="math inline">\(\alpha\)</span> test, we set this equal to <span class="math inline">\(\alpha\)</span> and solve for <span class="math inline">\(c\)</span> to get</p>
<p><span class="math display">\[c = \frac{\sigma \Phi^{-1} (1 - \alpha)}{\sqrt{n}}\]</span></p>
<p>We reject <span class="math inline">\(H_0\)</span> when</p>
<p><span class="math display">\[\bar{X} &gt; \frac{\sigma \Phi^{-1} (1 - \alpha)}{\sqrt{n}}\]</span></p>
<p>Equivalently, we reject when</p>
<p><span class="math display">\[\frac{\sqrt{n}(\bar{X} - 0)}{\sigma} &gt; z_\alpha\]</span></p>
<p>where <span class="math inline">\(z_\alpha = \Phi^{-1} (1 - \alpha)\)</span>.</p>
<p>Ideally we find the test with the highest power under <span class="math inline">\(H_1\)</span> among all size <span class="math inline">\(\alpha\)</span> tests. In practice, we use many of the same commonly used tests.</p>
</div>
<div id="wald-test" class="section level3 hasAnchor" number="12.5.5">
<h3><span class="header-section-number">12.5.5</span> Wald test<a href="classic-inference.html#wald-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(\theta\)</span> be a scalar parameter, let <span class="math inline">\(\hat{\theta}\)</span> be an estimate of <span class="math inline">\(\theta\)</span>, and let <span class="math inline">\(\widehat{\se}\)</span> be the estimated standard error of <span class="math inline">\(\hat{\theta}\)</span>. Consider testing</p>
<p><span class="math display">\[H_0: \theta = \theta_0 \quad \text{versus} \quad H_1: \theta \neq \theta_0\]</span></p>
<p>Assume that <span class="math inline">\(\hat{\theta}\)</span> is asymptotically Normal:</p>
<p><span class="math display">\[\frac{\hat{\theta} - \theta_0}{\widehat{\se}} \leadsto N(0,1)\]</span></p>
<p>The size <span class="math inline">\(\alpha\)</span> Wald test is: reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(|W| &gt; z_{\alpha / 2}\)</span> where</p>
<p><span class="math display">\[W = \frac{\hat{\theta} - \theta_0}{\widehat{\se}}\]</span></p>
<p>This test statistic follows the Normal distribution.</p>
<div id="power-of-the-wald-test" class="section level4 hasAnchor" number="12.5.5.1">
<h4><span class="header-section-number">12.5.5.1</span> Power of the Wald test<a href="classic-inference.html#power-of-the-wald-test" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Suppose the true value of <span class="math inline">\(\theta\)</span> is <span class="math inline">\(\theta_* \neq \theta_0\)</span>. The power <span class="math inline">\(\beta(\theta_*)\)</span> â the probability of correctly rejecting the null hypothesis â is given (approximately) by</p>
<p><span class="math display">\[1 - \Phi \left( \frac{\hat{\theta} - \theta_0}{\widehat{\se}} + z_{\alpha/2} \right) + \Phi \left( \frac{\hat{\theta} - \theta_0}{\widehat{\se}} - z_{\alpha/2} \right)\]</span></p>

<div class="rmdnote">
<p>Remember this is a two-tailed test. Essentially we are collecting the probability mass in the center of the standard normal distribution and subtracting that from 1, to get the area in the tails of the distribution. Hence, two-tailed test.</p>
</div>
<p>Recall that <span class="math inline">\(\widehat{\se}\)</span> tends to 0 as the sample size increases. So we can note that:</p>
<ul>
<li>The power is large if <span class="math inline">\(\theta_*\)</span> is far from <span class="math inline">\(\theta_0\)</span></li>
<li>The power is large if the sample size is large</li>
</ul>
<div class="example">
<p><span id="exm:unlabeled-div-191" class="example"><strong>Example 12.4  (Comparing two means) </strong></span>Let <span class="math inline">\(X_1, \ldots, X_m\)</span> and <span class="math inline">\(Y_1, \ldots, Y_n\)</span> be two independent samples from populations with means <span class="math inline">\(\mu_1, \mu_2\)</span> respectively. Letâs test the null hypothesis that <span class="math inline">\(\mu_1 = \mu_2\)</span>. Write this as</p>
<p><span class="math display">\[H_0: \delta = 0 \quad \text{versus} \quad H_1: \delta \neq 0\]</span></p>
<p>where <span class="math inline">\(\delta = \mu_1 - \mu_2\)</span>. The estimate of <span class="math inline">\(\delta\)</span> is <span class="math inline">\(\hat{\delta} = \bar{X} - \bar{Y}\)</span> with estimated standard error</p>
<p><span class="math display">\[\widehat{\se} = \sqrt{\frac{s_1^2}{m} + \frac{s_2^2}{n}}\]</span></p>
<p>where <span class="math inline">\(s_1^2\)</span> and <span class="math inline">\(s_2^2\)</span> are the sample variances. The size <span class="math inline">\(\alpha\)</span> Wald test rejects <span class="math inline">\(H_0\)</span> when <span class="math inline">\(|W| &gt; z_{\alpha / 2}\)</span> where</p>
<p><span class="math display">\[W = \frac{\hat{\delta} - 0}{\widehat{\se}} = \frac{\bar{X} - \bar{Y}}{\sqrt{\frac{s_1^2}{m} + \frac{s_2^2}{n}}}\]</span></p>
</div>
</div>
</div>
<div id="wald-or-t-test" class="section level3 hasAnchor" number="12.5.6">
<h3><span class="header-section-number">12.5.6</span> Wald or <span class="math inline">\(t\)</span>-test?<a href="classic-inference.html#wald-or-t-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To test <span class="math inline">\(H_0: \mu = \mu_0\)</span> where <span class="math inline">\(\mu = \E[X_i]\)</span> is the mean, we can use the Wald test. When the data are assumed to be Normal and the sample size is small, it is common to use the <span class="math inline">\(t\)</span>-test based on the <a href="general-random-variables.html#students-t-distribution">Studentâs <span class="math inline">\(t\)</span> distribution</a>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-192" class="definition"><strong>Definition 12.2  (Degrees of freedom) </strong></span>Generally defined as the number of observations minus the number of estimated parameters.</p>
</div>
</div>
<div id="relationship-to-confidence-intervals" class="section level3 hasAnchor" number="12.5.7">
<h3><span class="header-section-number">12.5.7</span> Relationship to confidence intervals<a href="classic-inference.html#relationship-to-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There is a relationship between the Wald test and the <span class="math inline">\(1 - \alpha\)</span> asymptotic confidence interval <span class="math inline">\(\hat{\theta} \pm \widehat{\se} z_{\alpha/2}\)</span>. The size <span class="math inline">\(\alpha\)</span> Wald test rejects <span class="math inline">\(H_0: \theta = \theta_0 \quad \text{versus} \quad \theta \neq \theta_0\)</span> if and only if <span class="math inline">\(\theta_0 \notin C\)</span> where</p>
<p><span class="math display">\[C = (\hat{\theta} - \widehat{\se}z_{\alpha / 2}, \hat{\theta} + \widehat{\se}z_{\alpha / 2})\]</span></p>
<p>Thus, testing the hypothesis is equivalent to checking whether the null value is in the confidence interval.</p>
</div>
<div id="statistical-vs.-scientific-significance" class="section level3 hasAnchor" number="12.5.8">
<h3><span class="header-section-number">12.5.8</span> Statistical vs.Â scientific significance<a href="classic-inference.html#statistical-vs.-scientific-significance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:scientific-sig"></span>
<img src="https://www.azquotes.com/picture-quotes/quote-the-absence-of-evidence-is-not-the-evidence-of-absence-carl-sagan-43-51-12.jpg" alt="Difference between statistical and scientific significance. Courtesy of Carl Sagan." width="90%" />
<p class="caption">
Figure 12.2: Difference between statistical and scientific significance. Courtesy of Carl Sagan.
</p>
</div>
<p>Rejecting <span class="math inline">\(H_0\)</span> indicates the result is <strong>statistically significant</strong>. That is, we have strong evidence to reject <span class="math inline">\(H_0\)</span>. The result or effect size can still be small if our test is powerful. In that situation, we have statistical significance but not necessarily scientific/substantive/practical significance. You should always be concerned with both of these types of significance. Statistical significance alone is not necessarily a useful or informative finding.</p>
</div>
</div>
<div id="p-values" class="section level2 hasAnchor" number="12.6">
<h2><span class="header-section-number">12.6</span> <span class="math inline">\(p\)</span>-values<a href="classic-inference.html#p-values" class="anchor-section" aria-label="Anchor link to header"></a></h2>

<div class="rmdwarning">
I hesitate to delve too deeply into <span class="math inline">\(p\)</span>-values in this camp. <span class="math inline">\(p\)</span>-values are <a href="https://amstat.tandfonline.com/doi/full/10.1080/00031305.2016.1154108">increasingly problematic</a> due to their improper usage. That said, you will see them all the time in published research so you need to understand how to properly use and interpret them.
</div>
<p>We could use a more fine-grained measure of the evidence against the null hypothesis. Generally, if the test rejects at level <span class="math inline">\(\alpha\)</span> it will also reject at level <span class="math inline">\(\alpha&#39; &gt; \alpha\)</span>. Hence, there is the smallest <span class="math inline">\(\alpha\)</span> at which the test rejects and we call this number the <span class="math inline">\(p\)</span>-value. Informally, the smaller the <span class="math inline">\(p\)</span>-value, the stronger the evidence against <span class="math inline">\(H_0\)</span>. Remember that this <span class="math inline">\(\alpha\)</span> will be a function of the power of the test, so both the magnitude of the difference between <span class="math inline">\(\theta_*\)</span> and <span class="math inline">\(\theta_0\)</span> and the sample size will influence this value.</p>
<div id="interpreting-p-values" class="section level3 hasAnchor" number="12.6.1">
<h3><span class="header-section-number">12.6.1</span> Interpreting <span class="math inline">\(p\)</span>-values<a href="classic-inference.html#interpreting-p-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>

<div class="rmdwarning">
Again - this is not really a great usage of <span class="math inline">\(p\)</span>-values, but they are extremely common thresholds that you will see researchers use.
</div>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(p\)</span>-value</th>
<th>evidence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(&lt; .01\)</span></td>
<td>very strong evidence against <span class="math inline">\(H_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(.01 - .05\)</span></td>
<td>strong evidence against <span class="math inline">\(H_0\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(.05 - .10\)</span></td>
<td>weak evidence against <span class="math inline">\(H_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(&gt; .1\)</span></td>
<td>little or no evidence against <span class="math inline">\(H_0\)</span></td>
</tr>
</tbody>
</table>

<div class="rmdnote">
<ul>
<li>These values are informal standards. There is no rhyme or reason they have to be so</li>
<li>A large <span class="math inline">\(p\)</span>-value is not strong evidence in favor of <span class="math inline">\(H_0\)</span>
<ul>
<li><span class="math inline">\(H_0\)</span> could be true</li>
<li><span class="math inline">\(H_0\)</span> is false but the test has low power</li>
</ul></li>
<li><span class="math inline">\(p\)</span>-value is not <span class="math inline">\(\Pr (H_0 | \text{Data})\)</span>. The <span class="math inline">\(p\)</span>-value is not the probability that the null hypothesis is true</li>
</ul>
</div>
</div>
<div id="calculating-p-values" class="section level3 hasAnchor" number="12.6.2">
<h3><span class="header-section-number">12.6.2</span> Calculating <span class="math inline">\(p\)</span>-values<a href="classic-inference.html#calculating-p-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that the size <span class="math inline">\(\alpha\)</span> test is of the form</p>
<p><span class="math display">\[\text{reject } H_0 \text{ if and only if } T(X_n) \geq c_\alpha\]</span></p>
<p>Then,</p>
<p><span class="math display">\[\text{p-value} = \text{sup}_{\theta \in \Theta_0} \Pr_\theta (T(X^n) \geq T(x^n))\]</span></p>
<p>where <span class="math inline">\(x^n\)</span> is the observed value of <span class="math inline">\(X^n\)</span>. If <span class="math inline">\(\Theta_0 = \{ \theta_0 \}\)</span> then</p>
<p><span class="math display">\[\text{p-value} = \Pr_{\theta_0} (T(X^n) \geq T(x^n))\]</span></p>
<p>Informally, the <span class="math inline">\(p\)</span>-value is the probability under <span class="math inline">\(H_0\)</span> of observing a value of the test statistic the same as or more extreme then what was actually observed.</p>
<div id="p-value-for-wald-test" class="section level4 hasAnchor" number="12.6.2.1">
<h4><span class="header-section-number">12.6.2.1</span> <span class="math inline">\(p\)</span>-value for Wald test<a href="classic-inference.html#p-value-for-wald-test" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let</p>
<p><span class="math display">\[w = \frac{\hat{\theta} - \theta_0}{\widehat{\se}}\]</span></p>
<p>denote the observed value of the Wald statistic <span class="math inline">\(W\)</span>. The <span class="math inline">\(p\)</span>-value is given by</p>
<p><span class="math display">\[\text{p-value} = \Pr_{\theta_0} (|W| &gt; |w|) \approx \Pr (|Z| &gt; |w| = 2 \Phi(-|w|)\]</span></p>
<p>where <span class="math inline">\(Z \sim N(0,1)\)</span>.</p>
<p><img src="12-frequentist-inference_files/figure-html/wald-p-val-1.png" width="90%" style="display: block; margin: auto;" /></p>
<div class="example">
<p><span id="exm:unlabeled-div-193" class="example"><strong>Example 12.5  (Cholesterol data) </strong></span>Consider a set of 371 individuals in a health study examining cholesterol levels (in mg/dl). 320 individuals have narrowing of the arteries, while 51 patients have no evidence of heart disease. Is the mean cholesterol different in the two groups?</p>
<p>Let the estimated mean cholesterol levels for the first group be <span class="math inline">\(\bar{X} = 216.2\)</span> and for the second group <span class="math inline">\(\bar{Y} = 195.3\)</span>. Let the estimated standard error for each group be <span class="math inline">\(\widehat{\se}(\hat{\mu}_1) = 5.0\)</span> and <span class="math inline">\(\widehat{\se}(\hat{\mu}_2) = 2.4\)</span>. The Wald test statistic is</p>
<p><span class="math display">\[W = \frac{\hat{\delta} - 0}{\widehat{\se}} = \frac{\bar{X} - \bar{Y}}{\sqrt{\widehat{\se}_1^2 + \widehat{\se}_2^2}} = \frac{216.2 - 195.3}{\sqrt{5^2 + 2.4^2}} = 3.78\]</span></p>
<p>To compute the <span class="math inline">\(p\)</span>-value, let <span class="math inline">\(Z \sim N(0,1)\)</span> denote a standard Normal random variable. Then</p>
<p><span class="math display">\[\text{p-value} = \Pr (|Z| &gt; 3.78) = 2 \Pr(Z &lt; -3.78) = 0.0002\]</span></p>
<p>which is very strong evidence against the null hypothesis.</p>
</div>
</div>
</div>
<div id="pearsons-chi2-test-for-multinomial-data" class="section level3 hasAnchor" number="12.6.3">
<h3><span class="header-section-number">12.6.3</span> Pearsonâs <span class="math inline">\(\chi^2\)</span> test for multinomial data<a href="classic-inference.html#pearsons-chi2-test-for-multinomial-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pearsonâs <span class="math inline">\(\chi^2\)</span> test is used for multinomial data. Recall that if <span class="math inline">\(X = (X_1, \ldots, X_k)\)</span> has a multinomial <span class="math inline">\((n,p)\)</span> distribution, then the MLE of <span class="math inline">\(p\)</span> is <span class="math inline">\(\hat{p} = (\hat{p}_1, \ldots, \hat{p}_k) = (x_1 / n, \ldots, x_k / n)\)</span>.</p>
<p>Let <span class="math inline">\(p_0 = (p_{01}, \ldots, p_{0k})\)</span> be some fixed vector and suppose we want to test</p>
<p><span class="math display">\[H_0: p = p_0 \quad \text{versus} \quad H_1: p \neq p_0\]</span></p>
<p>Pearsonâs <span class="math inline">\(\chi^2\)</span> statistic is</p>
<p><span class="math display">\[T = \sum_{j=1}^k \frac{(X_j - np_{0j})^2}{np_{0j}} = \sum_{j=1}^k \frac{(X_j - \E[X_j])^2}{\E[X_j]}\]</span></p>
<p>where <span class="math inline">\(\E[X_j] = \E[X_j] = np_{0j}\)</span> is the expected value under <span class="math inline">\(H_0\)</span>.</p>
<div id="example-attitudes-towards-abortion" class="section level4 hasAnchor" number="12.6.3.1">
<h4><span class="header-section-number">12.6.3.1</span> Example: Attitudes towards abortion<a href="classic-inference.html#example-attitudes-towards-abortion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><span class="math inline">\(H_A\)</span> - In a comparison of individuals, liberals are more likely to favor allowing a woman to obtain an abortion for any reason than conservatives</li>
<li><span class="math inline">\(H_0\)</span> - There is no difference in support between liberals and conservatives for allowing a woman to obtain an abortion for any reason. Any difference is the result of random sampling error.</li>
</ul>
<p>Say the null hypothesis is correct - there are no differences between ideological groups and attitudes towards abortion. What would the table look like?<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a></p>
<table>
<thead>
<tr class="header">
<th>Right to Abortion</th>
<th>Liberal</th>
<th>Moderate</th>
<th>Conservative</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Yes</td>
<td>40.8%</td>
<td>40.8%</td>
<td>40.8%</td>
<td>40.8%</td>
</tr>
<tr class="even">
<td></td>
<td>(206.45)</td>
<td>(289.68)</td>
<td>(271.32)</td>
<td>(768)</td>
</tr>
<tr class="odd">
<td>No</td>
<td>59.2%</td>
<td>59.2%</td>
<td>59.2%</td>
<td>59.2%</td>
</tr>
<tr class="even">
<td></td>
<td>(299.55)</td>
<td>(420.32)</td>
<td>(393.68)</td>
<td>(1113)</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>26.9%</td>
<td>37.7%</td>
<td>35.4%</td>
<td>100%</td>
</tr>
<tr class="even">
<td></td>
<td>(506)</td>
<td>(710)</td>
<td>(665)</td>
<td>(1881)</td>
</tr>
</tbody>
</table>
<p>In truth, what does our table actually look like?</p>
<table>
<thead>
<tr class="header">
<th>Right to Abortion</th>
<th>Liberal</th>
<th>Moderate</th>
<th>Conservative</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Yes</td>
<td>62.6%</td>
<td>36.6%</td>
<td>28.7%</td>
<td>40.8%</td>
</tr>
<tr class="even">
<td></td>
<td>(317)</td>
<td>(260)</td>
<td>(191)</td>
<td>(768)</td>
</tr>
<tr class="odd">
<td>No</td>
<td>37.4%</td>
<td>63.4%</td>
<td>71.28%</td>
<td>59.2%</td>
</tr>
<tr class="even">
<td></td>
<td>(189)</td>
<td>(450)</td>
<td>(474)</td>
<td>(1113)</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>26.9%</td>
<td>37.7%</td>
<td>35.4%</td>
<td>100%</td>
</tr>
<tr class="even">
<td></td>
<td>(506)</td>
<td>(710)</td>
<td>(665)</td>
<td>(1881)</td>
</tr>
</tbody>
</table>
<p>How can we test if these differences are statistically significant? That is, how do we test to see if we can reject the null hypothesis?</p>
<table>
<colgroup>
<col width="28%" />
<col width="22%" />
<col width="13%" />
<col width="14%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th>Right to Abortion</th>
<th></th>
<th>Liberal</th>
<th>Moderate</th>
<th>Conservative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Yes</td>
<td>Observed Frequency (<span class="math inline">\(X_j\)</span>)</td>
<td>317.0</td>
<td>260.0</td>
<td>191.0</td>
</tr>
<tr class="even">
<td></td>
<td>Expected Frequency (<span class="math inline">\(\E[X_j]\)</span>)</td>
<td>206.6</td>
<td>289.9</td>
<td>271.5</td>
</tr>
<tr class="odd">
<td></td>
<td><span class="math inline">\(X_j - \E[X_j]\)</span></td>
<td>110.4</td>
<td>-29.9</td>
<td>-80.5</td>
</tr>
<tr class="even">
<td></td>
<td><span class="math inline">\((X_j - \E[X_j])^2\)</span></td>
<td>12188.9</td>
<td>893.3</td>
<td>6482.7</td>
</tr>
<tr class="odd">
<td></td>
<td><span class="math inline">\(\frac{(X_j - \E[X_j])^2}{\E[X_j]}\)</span></td>
<td><strong>59.0</strong></td>
<td><strong>4.1</strong></td>
<td><strong>23.9</strong></td>
</tr>
<tr class="even">
<td>No</td>
<td>Observed Frequency (<span class="math inline">\(X_j\)</span>)</td>
<td>189.0</td>
<td>450.0</td>
<td>474.0</td>
</tr>
<tr class="odd">
<td></td>
<td>Expected Frequency (<span class="math inline">\(\E[X_j]\)</span>)</td>
<td>299.4</td>
<td>420.1</td>
<td>393.5</td>
</tr>
<tr class="even">
<td></td>
<td><span class="math inline">\(X_j - \E[X_j]\)</span></td>
<td>-110.4</td>
<td>29.9</td>
<td>80.5</td>
</tr>
<tr class="odd">
<td></td>
<td><span class="math inline">\((X_j - \E[X_j])^2\)</span></td>
<td>12188.9</td>
<td>893.3</td>
<td>6482.7</td>
</tr>
<tr class="even">
<td></td>
<td><span class="math inline">\(\frac{(X_j - \E[X_j])^2}{\E[X_j]}\)</span></td>
<td><strong>40.7</strong></td>
<td><strong>2.1</strong></td>
<td><strong>16.5</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>Calculating test statistic
<ul>
<li><span class="math inline">\(\chi^2=\sum{\frac{(X_j - \E[X_j])^2}{\E[X_j]}}=145.27\)</span></li>
<li><span class="math inline">\(\text{Degrees of freedom} = (\text{number of rows}-1)(\text{number of columns}-1)=2\)</span></li>
</ul></li>
<li>Calculating <span class="math inline">\(p\)</span>-value
<ul>
<li><span class="math inline">\(\text{p-value} = \Pr (\chi_2^2 &gt; 145.27) = 0\)</span></li>
<li>The probability that the null hypothesis is true and the observed frequencies are the result of random sampling error is less than 1 in a quintillion. Extremely extremely unlikely the null hypothesis is true.</li>
</ul></li>
</ul>

</div>
</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bertsekas2008" class="csl-entry">
Bertsekas, Dimitri P, and John N Tsitsiklis. 2008. <span>âIntroduction to Probability.â</span>
</div>
<div id="ref-wasserman2013" class="csl-entry">
Wasserman, Larry. 2013. <em>All of Statistics: A Concise Course in Statistical Inference</em>. Springer Science &amp; Business Media. <a href="https://link-springer-com.proxy.uchicago.edu/book/10.1007/978-0-387-21736-9">https://link-springer-com.proxy.uchicago.edu/book/10.1007/978-0-387-21736-9</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="22">
<li id="fn22"><p>Based on data from the 2008 American National Elections Study.<a href="classic-inference.html#fnref22" class="footnote-back">â©ï¸</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="limits.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mle-ols.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ysheng-uc/notes/main/12-frequentist-inference.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
},
"theme": "readable",
"highlight": "pygment"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
